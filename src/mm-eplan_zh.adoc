[appendix]
== RVWMO解释材料，版本0.1
[[mm-explain]]

本节提供了关于RVWMO内存模型的更多解释，使用了更为通俗的语言和具体的例子。这些内容旨在澄清公理和程序顺序规则的意义和意图。本附录应视为注释性材料；所有规范性的内容已在<<内存模型>>部分以及ISA规范主体的其他部分中提供。所有已知的差异列在<<差异>>部分，其他差异为无意之举。

[[whyrvwmo]]
=== 为什么选择RVWMO？

内存一致性模型在从弱到强的范围内有所不同。弱一致性模型允许更多的硬件实现灵活性，并且在性能、每瓦性能、功耗、可扩展性和硬件验证开销方面，往往优于强一致性模型，但代价是编程模型更加复杂。强一致性模型提供了更简单的编程模型，但限制了在流水线和内存系统中可以执行的（非推测性）硬件优化，这也意味着在功耗、面积和验证开销方面的代价。

RISC-V选择了RVWMO内存模型，它是发布一致性的一个变体，介于内存模型范围的两端。RVWMO内存模型使得架构师可以构建简单的实现、激进的实现、嵌入在更大系统中的实现，或者任何其他可能的实现，同时仍然足够强大，支持高性能的编程语言内存模型。

为了促进从其他架构移植代码，一些硬件实现可能选择实现Ztso扩展，它默认提供更严格的RVTSO顺序语义。针对RVWMO编写的代码自动与RVTSO兼容，但假设RVTSO的代码无法保证在RVWMO实现上正确运行。事实上，大多数RVWMO实现将（且应该）直接拒绝运行仅支持RVTSO的二进制文件。因此，每个实现必须决定是优先考虑与RVTSO代码的兼容性（例如，为了促进从x86的移植），还是优先考虑与其他实现RVWMO的RISC-V内核的兼容性。

对于针对RVWMO编写的代码中的某些屏障和/或内存排序注释，可能在RVTSO下变得多余；RVWMO默认在Ztso实现上产生的开销是获取这些屏障的增量开销（例如，FENCE R,RW和FENCE RW,W），在该实现上这些操作将变为无操作。然而，如果需要与非Ztso实现的兼容性，这些屏障必须保留在代码中。

[[litmustests]]
=== 试纸测试

本章的解释使用了 _试纸测试_，即一段小型程序，旨在测试或突出内存模型的某个特定方面。<<litmus-sample>>展示了一个包含两个 hart 的试纸测试示例。对于该图以及本章接下来的所有图，我们假设 s0-s2在所有hart中预设为相同的值，且 s0保存地址 x， s1保存地址 y， s2保存地址 z，其中 x、 y和 z是对齐到8字节边界的不重叠内存位置。其他所有寄存器和所有引用的内存位置都假定初始化为零。每个图显示了试纸测试代码在左侧，右侧则是某一有效或无效执行的可视化。

[[litmus-sample, 试纸测试示例]]
[float="center",align="center",cols="1a,.^1a",frame="none",grid="none",options="noheader"]
.一个简单的试纸测试及一个无效执行 (`a0=1`).
|===
|
[.left]
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header"]
!===
2+!Hart 0 2+!Hart 1 
! !&#8942; ! !&#8942;
! !li t1,1 ! !li t4,4
!(a) !sw t1,0(s0) !(e) !sw t4,0(s0)
! !&#8942; ! !&#8942;
! !li t2,2 ! !
!(b) !sw t2,0(s0) ! !
! !&#8942; ! !&#8942;
!(c) !lw a0,0(s0) ! !
! !&#8942; ! !&#8942;
! !li t3,3 ! !li t5,5
!(d) !sw t3,0(s0) !(f) !sw t5,0(s0)
! !&#8942; ! !&#8942;
!===
|
!===
//a! graphviz::images/graphviz/litmus_sample.txt[]
a! image::graphviz/litmus_sample.png[]
!===
|===

试纸测试用于理解内存模型在特定具体情境下的影响。例如，在 <<litmus-sample>> 中，第一 hart 上 a0 的最终值可以是 2、4 或 5，具体取决于每个 hart 的指令流在运行时的动态交错。然而，在这个例子中，第一 hart 上 a0 的最终值永远不会是 1 或 3；直观地说，值 1 在加载指令执行时已经不可见，而值 3 在加载指令执行时还不可见。我们将分析这个测试以及其他的测试。

<<<
[[litmus-key]]
.本附录中绘制的 litmus 测试图的符号说明
[%autowidth,cols="<,<",align="center",float="center",options="header",]
|===
|边缘 |完整名称（以及解释）
|rf |读取来源（从每个存储到返回该存储写入值的加载）

|co |一致性（每个地址的存储之间的全序关系）

|fr |从读取（从每个加载到存储，返回该存储值的共后继）

|ppo |保留程序顺序

|fence |由 FENCE 指令强制执行的顺序

|addr |地址依赖性

|ctrl |控制依赖性

|data |数据依赖性
|===

图表位于每个 litmus 测试的右侧，显示了正在考虑的特定执行候选的可视化表示。这些图表使用一种在内存模型文献中常见的符号表示法，用于约束可能产生此执行的全局内存顺序集合。它也是本手册中 _herd_ 模型的基础。此符号表示法在 <<litmus-key>> 中有详细解释。在列出的关系中，rf 边缘、co 边缘、fr 边缘和 ppo 边缘直接约束全局内存顺序（fence、addr、data 以及某些 ctrl 边缘也通过 ppo 约束）。其他边缘（如同 hart 内的 rf 边缘）提供信息，但不直接约束全局内存顺序。

例如，在 <<litmus-sample>> 中，`a0=1` 只有在以下情况之一为真时才会发生：

* (b) 出现在 (a) 之前的全局内存顺序中（并且在一致性顺序中 co）。但是，这违反了 RVWMO 的 PPO 规则 `ppo:->st`。从 (b) 到 (a) 的 co 边缘突出了这一矛盾。
* (a) 出现在 (b) 之前的全局内存顺序中（并且在一致性顺序中 co）。但是，在这种情况下，加载值公理会被违反，因为 (a) 不是在程序顺序中 (c) 之前的最新匹配存储。从 (c) 到 (b) 的 fr 边缘突出了这一矛盾。

由于这两种情况都不满足 RVWMO 公理，因此 `a0=1` 结果是被禁止的。

除了本附录中描述的内容外，还有一个包含超过七千个 litmus 测试的测试套件，位于 https://github.com/litmus-tests/litmus-tests-riscv。
[NOTE]
====
litmus 测试库还提供了如何在 RISC-V 硬件上运行 litmus 测试以及如何将结果与操作模型和公理模型进行比较的说明。

未来，我们预计将这些内存模型 litmus 测试适配为 RISC-V 合规性测试套件的一部分。
====
=== 解释 RVWMO 规则

本节提供了对所有 RVWMO 规则和公理的解释和示例。

==== 保留程序顺序和全局内存顺序

保留程序顺序表示必须在全局内存顺序中遵守的程序顺序子集。从概念上讲，同一个 hart 中的事件，如果它们由保留程序顺序排序，则必须从其他 hart 和/或观察者的角度按该顺序出现。另一方面，同一个 hart 中的事件，如果它们不受保留程序顺序的限制，则可以在其他 hart 和/或观察者的角度重新排序。

非正式地说，全局内存顺序表示加载和存储执行的顺序。正式的内存模型文献已经不再以执行为基础构建规范，但这一概念仍然对建立直观的理解非常有用。加载执行是指其返回值已确定。存储执行则不仅仅指它已经在流水线中执行，而是指它的值已经传播到全局可见的内存中。从这个角度看，全局内存顺序还代表了一致性协议和/或内存系统的贡献，它们将每个 hart 发出的（可能已重新排序的）内存访问交织成一个所有 hart 一致同意的全局总顺序。

加载执行的顺序并不总是直接对应于这两个加载返回值的相对时间顺序。特别是，一个加载 _b_ 可能在另一个加载 _a_ 之前执行（即 _b_ 可能先执行 _a_ ，并且 _b_ 可能在全局内存顺序中出现在 _a_ 之前），但 _a_ 仍然可能返回比 _b_ 更旧的值。这种不一致反映了（其中之一）缓冲区对核心和内存之间的影响。例如，_b_ 可能从存储缓冲区返回一个值，而 _a_ 则忽略了这个更新的存储，从内存中读取一个更旧的值。为了考虑这一点，在每次加载执行时，它返回的值是由加载值公理决定的，而不仅仅是通过确定全局内存顺序中最接近的存储来严格确定。

[[loadvalueaxiom, 加载值公理]]
==== 加载值公理

[IMPORTANT]
====
<<ax-load>>: 每个加载 _i_ 返回的每个字节的值是由以下商定的、在全局内存顺序中最新的写入该字节的存储决定的：

. 写入该字节且在全局内存顺序中先于 _i_ 的存储
. 写入该字节且在程序顺序中先于 _i_ 的存储
====

保留程序顺序 _不是_ 必须尊重一个存储后跟一个加载的顺序，前提是它们访问的是重叠地址。这种复杂性源自几乎所有实现中存储缓冲区的普遍存在。非正式地说，加载可能通过从存储缓冲区转发返回值，虽然该存储仍然在存储缓冲区中，而不是已经写回全局内存。因此，其他 hart 可能会观察到加载在存储之前执行。

考虑 <<litms_sb_forward>>。在具有存储缓冲区的实现上运行该程序时，可能会得到最终结果 a0=1，`a1=0`，a2=1，`a3=0`，其执行过程如下：

[[litms_sb_forward]]
.存储缓冲区转发 litmus 测试（允许的结果）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",align="center"]
!===
2+^!Hart 0 2+^!Hart 1
2+^!li t1, 1 2+^!li t1, 1
2+<!(a) sw t1,0(s0) 2+!(e) sw t1,0(s1)
2+<!(b) lw a0,0(s0) 2+!(f) lw a2,0(s1)
2+<!(c) fence r,r 2+!(g) fence r,r
2+<!(d) lw a1,0(s1) 2+!(h) lw a3,0(s0)
4+^!Outcome: `a0=1`, `a1=0`, `a2=1`, `a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_sb_fwd.txt[]
a! image::graphviz/litmus_sb_fwd.png[]
!===
|===

* (a) 执行并进入第一个 hart 的私有存储缓冲区
* (b) 执行并从 (a) 中通过存储缓冲区转发其返回值 1
* (c) 执行，因为之前的所有加载（即 (b)）都已完成
* (d) 执行并从内存中读取值 0
* (e) 执行并进入第二个 hart 的私有存储缓冲区
* (f) 执行并从 (e) 中通过存储缓冲区转发其返回值 1
* (g) 执行，因为之前的所有加载（即 (f)）都已完成
* (h) 执行并从内存中读取值 0
* (a) 从第一个 hart 的存储缓冲区排出到内存
* (e) 从第二个 hart 的存储缓冲区排出到内存

因此，内存模型必须能够解释这种行为。

换句话说，假设保留程序顺序的定义包括以下假设规则：如果内存访问 _a_ 在程序顺序中先于内存访问 _b_，并且 _a_ 和 _b_ 访问相同的内存位置，_a_ 是写操作，_b_ 是读操作，那么 _a_ 在保留程序顺序中先于 _b_（因此也在全局内存顺序中先于 _b_）。称之为“规则 X”。那么我们得到以下结果：

* (a) 先于 (b)：根据规则 X
* (b) 先于 (d)：根据规则 <<overlapping-ordering, 4>>
* (d) 先于 (e)：根据加载值公理。否则，如果 (e) 先于 (d)，那么 (d) 将被要求返回值 1。（这是一个完全合法的执行；只是这不是我们讨论的执行）
* (e) 先于 (f)：根据规则 X
* (f) 先于 (h)：根据规则 <<overlapping-ordering, 4>>
* (h) 先于 (a)：根据加载值公理，如上所述。

全局内存顺序必须是一个总顺序，不能是循环的，因为循环意味着循环中的每个事件都发生在自身之前，这是不可能的。因此，上述提议的执行将被禁止，因此添加规则 X 将禁止具有存储缓冲区转发的实现，这显然是不可取的。

尽管如此，即使在全局内存顺序中 (b) 先于 (a) 和/或 (f) 先于 (e)，在这个例子中唯一合理的可能性是 (b) 返回 (a) 写入的值，同样 (f) 返回 (e) 写入的值。这种情况组合导致了加载值公理定义中的第二种选择。即使在全局内存顺序中 (b) 先于 (a)，由于 (a) 在 (b) 执行时仍在存储缓冲区中，因此 (a) 对 (b) 仍然可见。因此，即使在全局内存顺序中 (b) 先于 (a)，(b) 也应该返回 (a) 写入的值，因为在程序顺序中 (a) 先于 (b)。同样适用于 (e) 和 (f)。

[[litmus_ppoca]]
.用于测试存储缓冲区行为的关键
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
.用于测试存储缓冲区转发行为的 PPOCA 试纸测试（允许的结果）
|===
|
[%autowidth,cols="^,<,^,<",options="header",float="center",align="center"]
!===
2+^!Hart 0 2+^!Hart 1
! !li t1, 1 !!li t1, 1
!(a) !sw t1,0(s0) !!LOOP:
!(b) !fence w,w !(d) !lw a0,0(s1)
!(c) !sw t1,0(s1) !!beqz a0, LOOP
2+! !(e) !sw t1,0(s2)
2+! !(f) !lw a1,0(s2)
2+! ! !xor a2,a1,a1
2+! ! !add s0,s0,a2
2+! !(g) !lw a2,0(s0)
4+!Outcome: `a0=1`, `a1=1`, `a2=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_ppoca.txt[]
a! image::graphviz/litmus_ppoca.png[]
!===
|===

另一个用于测试存储缓冲区行为的测试如 <<litmus_ppoca>> 所示。在这个例子中，由于控制依赖性，(d) 在 (e) 之前排序，由于地址依赖性，(f) 在 (g) 之前排序。然而，(e) 不一定在 (f) 之前排序，即使 (f) 返回 (e) 写入的值。这可能对应于以下事件顺序：

* (e) 推测性执行并进入第二个 hart 的私有存储缓冲区（但不排出到内存）
* (f) 推测性执行并从存储缓冲区中的 (e) 转发其返回值 1
* (g) 推测性执行并从内存中读取值 0
* (a) 执行，进入第一个 hart 的私有存储缓冲区，并排出到内存
* (b) 执行并退休
* (c) 执行，进入第一个 hart 的私有存储缓冲区，并排出到内存
* (d) 执行并从内存中读取值 1
* (e)、(f) 和 (g) 提交，因为推测结果是正确的
* (e) 从存储缓冲区排出到内存

[[atomicityaxiom]]
==== 原子性公理

[]
====
<<ax-atom, 原子性公理>>（对齐原子操作）：如果 r 和 w 是由硬件线程 h 中对齐的 LR 和 SC 指令生成的成对加载和存储操作，s 是对字节 x 的存储，并且 r 返回 s 写入的值，则 s 必须在全局内存顺序中位于 w 之前，并且在全局内存顺序中 s 和 w 之间不能有来自 h 以外的硬件线程对字节 x 的存储。
====

RISC-V 架构将原子性概念与排序概念分离。与 TSO 等架构不同，RISC-V 原子操作在 RVWMO 下默认不强制任何排序要求。排序语义仅由适用的 PPO 规则保证。

RISC-V 包含两种类型的原子操作：AMO 和 LR/SC 对。这两者在概念上表现不同。LR/SC 表现为旧值被带到核心，修改，然后写回内存，同时对该内存位置保持保留。AMO 则表现为直接在内存中执行。因此，AMO 本质上是原子的，而 LR/SC 对在原子性方面略有不同，即在原硬件线程保持保留期间，内存位置不会被其他硬件线程修改。

[frame=none]
|====
|(a) lr.d a0, 0(s0) |(a) lr.d a0, 0(s0) |(a) lr.w a0, 0(s0) |(a) lr.w a0, 0(s0)

|(b) sd t1, 0(s0)  |(b) sw t1, 4(s0)  |(b) sw t1, 4(s0) |(b) sw t1, 4(s0)

|(c) sc.d t3, t2, 0(s0) |(c) sc.d t3, t2, 0(s0) |(c) sc.w t3, t2, 0(s0) |(c) addi s0, s0, 8 

|(d) sc.w t3, t2, 8(s0)|||
|====
[[litmus_lrsdsc]]
<<litmus_lrsdsc, 图 4>>：在所有四个（独立）实例中，最终的条件存储指令允许但不保证成功。

原子性公理禁止其他硬件线程的存储在全局内存顺序中插入到 LR 和与该 LR 配对的 SC 之间。原子性公理不禁止加载在程序顺序或全局内存顺序中插入到配对操作之间，也不禁止来自同一硬件线程的存储或对非重叠位置的存储在程序顺序或全局内存顺序中出现在配对操作之间。例如，<<litmus_lrsdsc>> 中的 SC 指令可能（但不保证）成功。这些成功不会违反原子性公理，因为插入的非条件存储来自与配对的加载保留和条件存储指令相同的硬件线程。这样，跟踪内存访问的内存系统不会被迫失败条件存储指令，即使它碰巧与保持保留的内存位置共享同一缓存行的另一部分。

原子性公理还技术上支持 LR 和 SC 触及不同地址和/或使用不同访问大小的情况；然而，预计这种行为在实践中很少见。同样，LR/SC 对之间的存储实际重叠 LR 或 SC 引用的内存位置的情况预计比存储仅落在同一缓存行上的情况更少见。

[[mm-progress]]
==== 进展公理

[IMPORTANT]
====
<<ax-prog, 进展公理>>：在全局内存顺序中，任何内存操作之前都不能有无限序列的其他内存操作。
====

进展公理确保了最小的前进保证。它确保一个硬件线程的存储将在有限时间内最终对系统中的其他硬件线程可见，并且其他硬件线程的加载最终能够读取这些值（或其后继）。没有这个规则，例如，一个自旋锁可能会无限期地在一个值上旋转，即使有另一个硬件线程的存储等待解锁自旋锁。

进展公理旨在不对 RISC-V 实现中的硬件线程施加任何其他公平性、延迟或服务质量的概念。任何更强的公平性概念由 ISA 的其余部分和/或平台和/或设备定义和实现。

在几乎所有情况下，标准缓存一致性协议将自然满足前进公理。具有非一致性缓存的实现可能需要提供其他机制，以确保所有存储（或其后继）最终对所有硬件线程可见。

[[mm-overlap]]
==== 重叠地址排序（<<overlapping-ordering, 规则 1-3>>）

[NOTE]
====
<<overlapping-ordering, 规则 1>>：b 是存储，a 和 b 访问重叠的内存地址

<<overlapping-ordering, 规则 2>>：a 和 b 是加载，x 是 a 和 b 都读取的字节，在程序顺序中 a 和 b 之间没有对 x 的存储，并且 a 和 b 返回由不同内存操作写入的 x 的值

<<overlapping-ordering, 规则 3>>：a 是由 AMO 或 SC 指令生成的，b 是加载，并且 b 返回由 a 写入的值
====

后者是存储的同地址排序是直接的：加载或存储永远不能与后来的存储到重叠的内存位置重新排序。从微架构的角度来看，一般来说，如果推测被证明是无效的，撤销推测性重新排序的存储是困难或不可能的，因此模型简单地不允许这种行为。另一方面，从存储到后来的加载的同地址排序不需要强制执行。如<<loadvalueaxiom>>中所述，这反映了实现从缓冲存储转发值到后续加载的可观察行为。

同地址加载-加载排序要求要微妙得多。基本要求是，较年轻的加载不得返回比同一硬件线程中较旧的加载返回的值更旧的值。这通常被称为“CoRR”（加载-加载对的一致性），或作为更广泛的“同一位置的顺序一致性”要求的一部分。过去一些架构放宽了同地址加载-加载排序，但事后看来，这通常被认为使编程模型过于复杂，因此 RVWMO 要求强制执行 CoRR 排序。然而，由于全局内存顺序对应于加载执行的顺序，而不是返回值的顺序，因此需要一些间接方法来捕捉 CoRR 要求。

[[frirfi]]
.试纸测试 MP+fence.w.w+fri-rfi-addr（允许结果）

[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
.试纸测试 MP+fence.w.w+fre-rfi-addr（允许结果）
|===
|
[%autowidth,cols="^,<,^,<",options="header",float="center",align="center"]
!===
2+!硬件线程 0 2+^!硬件线程 1
!!li t1, 1 !!li t2, 2
>!(a) !sw t1,0(s0) >!(d) !lw a0,0(s1)
>!(b) !fence w, w >!(e) !sw t2,0(s1)
>!(c) !sw t1,0(s1) >!(f) !lw a1,0(s1)
! ! >!(g) !xor t3,a1,a1
! ! >!(h) !add s0,s0,t3
! ! >!(i) !lw a2,0(s0)
4+^!结果：`a0=1`，`a1=2`，`a2=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_mp_fenceww_fri_rfi_addr.txt[]
a! image::graphviz/litmus_mp_fenceww_fri_rfi_addr.png[]
!===
|===
考虑 <<frirfi>> 的试纸测试，这是更一般的“fri-rfi”模式的一个特定实例。“fri-rfi”一词指的是 (d)、(e)、(f) 的序列：(d)“从读取”（即从早期写入读取）(e) 是同一硬件线程，并且 (f) 从 (e) 读取，它们在同一硬件线程中。

从微架构的角度来看，结果 `a0=1`，`a1=2`，`a2=0` 是合法的（以及其他各种不太微妙的结果）。直观地说，以下将产生所讨论的结果：

* (d) 停顿（无论出于何种原因；可能是等待某些其他前面的指令）
* (e) 执行并进入存储缓冲区（但尚未排出到内存）
* (f) 执行并从存储缓冲区中的 (e) 转发
* (g)、(h) 和 (i) 执行
* (a) 执行并排出到内存，(b) 执行，(c) 执行并排出到内存
* (d) 解除停顿并执行
* (e) 从存储缓冲区排出到内存

这对应于 (f)、(i)、(a)、(c)、(d)、(e) 的全局内存顺序。注意，即使 (f) 在 (d) 之前执行，(f) 返回的值也比 (d) 返回的值更新。因此，这种执行是合法的，不违反 CoRR 要求。

同样，如果两个背靠背的加载返回由同一存储写入的值，则它们也可以在全局内存顺序中无序出现，而不会违反 CoRR。注意，这与说两个加载返回相同的值不同，因为两个不同的存储可能写入相同的值。

[[litmus-rsw]]
.试纸测试 RSW（允许结果）

[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<",options="header",float="center",align="center"]
!===
2+!Hart 0 2+^!Hart 1
2+!li t1, 1 >!(d) <!lw  a0,0(s1)
>!(a) <!sw t1,0(s0) >!(e) !xor t2,a0,a0
>!(b) <!fence w, w >!(f) !add s4,s2,t2
>!(c) <!sw t1,0(s1) >!(g) !lw  a1,0(s4)
! ! >!(h) !lw  a2,0(s2)
! ! >!(i) !xor t3,a2,a2
! ! >!(j) !add s0,s0,t3
! ! >!(k) !lw  a3,0(s0)
4+!Outcome: `a0=1`, `a1=v`, `a2=v`, `a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_rsw.txt[]
a! image::graphviz/litmus_rsw.png[]
!===
|===

考虑 <<litmus-rsw>> 的试纸测试。
结果 `a0=1`，`a1=v`，`a2=v`，`a3=0`（其中 _v_ 是由另一个硬件线程写入的某个值）可以通过允许 (g) 和 (h) 重新排序来观察到。这可能是推测性完成的，并且微架构可以通过嗅探缓存失效并发现没有失效来证明这种推测是合理的，因为在 (g) 之后重放 (h) 将返回相同存储写入的值。因此，假设 `a1` 和 `a2` 最终会得到相同存储写入的值，(g) 和 (h) 可以合法地重新排序。与此执行对应的全局内存顺序将是 (h)、(k)、(a)、(c)、(d)、(g)。

在 <<litmus-rsw>> 的测试中，`a1` 不等于 `a2` 的执行确实要求 (g) 在全局内存顺序中出现在 (h) 之前。允许 (h) 在全局内存顺序中出现在 (g) 之前在这种情况下会导致违反 CoRR，因为这样 (h) 将返回比 (g) 返回的值更旧的值。因此，<<overlapping-ordering, rule 2>> 禁止这种 CoRR 违规的发生。因此，<<overlapping-ordering, rule 2>> 在所有情况下强制执行 CoRR 的同时，足够弱以允许在实际微架构中常见的 "RSW" 和 "fri-rfi" 模式。

还有一个重叠地址规则：<<overlapping-ordering, rule 3>> 仅仅指出，在 AMO 或 SC 成功执行之前，不能将值从 AMO 或 SC 返回到后续加载。这在概念上自然地遵循 AMO 和 SC 指令旨在在内存中原子执行的观点。然而，值得注意的是，<<overlapping-ordering, rule 3>> 规定硬件甚至不能非推测性地将 AMOSWAP 存储的值转发到后续加载，即使对于 AMOSWAP，该存储值实际上并不依赖于内存中的先前值，其他 AMO 也是如此。同样，即使在 SC 存储值不依赖于配对 LR 返回的值时，从 SC 存储值转发到后续加载也是如此。

上述三个 PPO 规则也适用于仅部分重叠的内存访问。例如，当使用不同大小的访问来访问同一对象时可能会发生这种情况。还要注意，对于两个重叠的内存操作，基地址不一定相同。当使用未对齐的内存访问时，重叠地址 PPO 规则适用于每个组件内存访问。

[[mm-fence]]
==== Fences (<<overlapping-ordering, Rule 4>>)

[IMPORTANT]
====
规则 <<overlapping-ordering, 4>>：存在一个 FENCE 指令将 a 排在 b 之前
====

默认情况下，FENCE 指令确保程序顺序中栅栏之前的所有内存访问（“前驱集”）在全局内存顺序中出现在程序顺序中栅栏之后的内存访问（“后继集”）之前。然而，栅栏可以选择进一步限制前驱集和/或后继集到更小的内存访问集，以提供一些加速。具体来说，栅栏具有 PR、PW、SR 和 SW 位，这些位限制前驱集和/或后继集。前驱集仅在 PR（分别为 PW）设置时包括加载（分别为存储）。同样，后继集仅在 SR（分别为 SW）设置时包括加载（分别为存储）。

FENCE 编码目前有九种非平凡组合的四个位 PR、PW、SR 和 SW，加上一个额外的编码 FENCE.TSO，便于映射“获取+释放”或 RVTSO 语义。其余七种组合具有空的前驱集和/或后继集，因此是无操作的。在十种非平凡选项中，只有六种在实践中常用：

* FENCE RW,RW
* FENCE.TSO
* FENCE RW,W
* FENCE R,RW
* FENCE R,R
* FENCE W,W

使用任何其他 PR、PW、SR 和 SW 组合的 FENCE 指令是保留的。我们强烈建议程序员坚持使用这六种组合。其他组合可能与内存模型有未知或意外的交互。

最后，我们注意到，由于 RISC-V 使用多副本原子内存模型，程序员可以以线程本地的方式推理栅栏位。没有复杂的“栅栏累积性”概念，如在非多副本原子内存模型中发现的那样。

[[sec:memory:acqrel]]
==== 显式同步（<<overlapping-ordering, Rules 5-8>>）

[IMPORTANT]
====
<<overlapping-ordering, Rule 5>>：a 具有获取注释

<<overlapping-ordering, Rule 6>>：b 具有释放注释

<<overlapping-ordering, Rule 7>>：a 和 b 都具有 RCsc 注释

<<overlapping-ordering, Rule 8>>：a 与 b 配对
====

获取操作，如在关键部分开始时使用的操作，要求程序顺序中获取之后的所有内存操作也在全局内存顺序中跟随获取。这确保了，例如，关键部分内的所有加载和存储都与用于保护它的同步变量保持最新。获取排序可以通过两种方式之一强制执行：使用获取注释，仅对同步变量本身强制排序，或使用 FENCE R,RW，对所有先前的加载强制排序。

[[spinlock_atomics]]
.带有原子操作的自旋锁
[source%linenums,asm]
....
          sd           x1, (a1)     # 任意无关存储
          ld           x2, (a2)     # 任意无关加载
          li           t0, 1        # 初始化交换值。
      again:
          amoswap.w.aq t0, t0, (a0) # 尝试获取锁。
          bnez         t0, again    # 如果被持有则重试。
          # ...
          # 关键部分。
          # ...
          amoswap.w.rl x0, x0, (a0) # 通过存储 0 释放锁。
          sd           x3, (a3)     # 任意无关存储
          ld           x4, (a4)     # 任意无关加载
....

考虑 <<spinlock_atomics, 示例 1>>。
因为这个例子使用了 _aq_，所以关键部分中的加载和存储在全局内存顺序中保证出现在用于获取锁的 AMOSWAP 之后。然而，假设 `a0`、`a1` 和 `a2` 指向不同的内存位置，关键部分中的加载和存储在全局内存顺序中可能会或可能不会出现在示例开头的“任意无关加载”之后。

[[spinlock_fences]]
.带有栅栏的自旋锁
[source%linenums,asm]
....
          sd           x1, (a1)     # 任意无关存储
          ld           x2, (a2)     # 任意无关加载
          li           t0, 1        # 初始化交换值。
      again:
          amoswap.w    t0, t0, (a0) # 尝试获取锁。
          fence        r, rw        # 强制“获取”内存排序
          bnez         t0, again    # 如果被持有则重试。
          # ...
          # 关键部分。
          # ...
          fence        rw, w        # 强制“释放”内存排序
          amoswap.w    x0, x0, (a0) # 通过存储 0 释放锁。
          sd           x3, (a3)     # 任意无关存储
          ld           x4, (a4)     # 任意无关加载
....

现在，考虑 <<spinlock_fences, 示例 2>> 中的替代方案。在这种情况下，即使 AMOSWAP 没有使用 _aq_ 位强制排序，栅栏仍然强制获取 AMOSWAP 在全局内存顺序中出现在关键部分中的所有加载和存储之前。然而，请注意，在这种情况下，栅栏还强制执行其他排序：它还要求程序开头的“任意无关加载”在全局内存顺序中出现在关键部分的加载和存储之前。（然而，这个特定的栅栏并不强制与代码片段开头的“任意无关存储”相关的任何排序。）通过这种方式，栅栏强制的排序比 _aq_ 强制的排序稍微粗糙一些。

释放排序与获取排序完全相同，只是方向相反。释放语义要求程序顺序中释放操作之前的所有加载和存储也在全局内存顺序中出现在释放操作之前。这确保了，例如，关键部分中的内存访问在全局内存顺序中出现在释放锁存储之前。与获取语义一样，释放语义可以使用释放注释或 FENCE RW,W 操作强制执行。使用相同的示例，关键部分中的加载和存储与代码片段末尾的“任意无关存储”之间的排序仅由 <<spinlock_fences, 示例 2>> 中的 FENCE RW,W 强制执行，而不是由 <<spinlock_atomics, 示例 1>> 中的 _rl_ 强制执行。

仅使用 RCpc 注释，存储释放到加载获取的排序不会强制执行。这有助于移植在 TSO 和/或 RCpc 内存模型下编写的代码。要强制存储释放到加载获取的排序，代码必须使用存储释放-RCsc 和加载获取-RCsc 操作，以便 PPO 规则 7 适用。仅使用 RCpc 对 C/C++ 中的许多用例是足够的，但对 C/C++、Java 和 Linux 中的许多其他用例是不足够的，仅举几个例子；有关详细信息，请参见 <<memory_porting, 内存移植>>。

PPO 规则 8 表示 SC 必须在全局内存顺序中出现在其配对的 LR 之后。这将自然地从 LR/SC 的常见用法中得出，以执行原子读-修改-写操作，因为固有的数据依赖性。然而，即使存储的值在语法上不依赖于配对 LR 返回的值，PPO 规则 8 也适用。

最后，我们注意到，与栅栏一样，程序员在分析排序注释时不必担心“累积性”。

[[sec:memory:dependencies]]
==== 句法依赖（<<overlapping-ordering, 规则 9-11>>）

[[ppo-addr]]
[IMPORTANT]
====
<<overlapping-ordering, 规则 9>>：b 对 a 有句法地址依赖

<<overlapping-ordering, 规则 10>>：b 对 a 有句法数据依赖

<<overlapping-ordering, 规则 11>>：b 是存储操作，且 b 对 a 有句法控制依赖
====

RVWMO 内存模型尊重从加载到同一 hart 中后续内存操作的依赖关系。Alpha 内存模型以选择 _不_ 强制执行此类依赖关系的顺序而著称，但大多数现代硬件和软件内存模型认为允许重新排序依赖指令过于混乱和不直观。此外，现代代码有时会故意使用此类依赖关系作为一种特别轻量级的排序强制机制。

<<mem-dependencies>> 中的术语如下工作。指令被认为从其源寄存器携带依赖关系到其目标寄存器，只要写入每个目标寄存器的值是源寄存器的函数。对于大多数指令，这意味着目标寄存器携带来自所有源寄存器的依赖关系。然而，有一些显著的例外。在内存指令的情况下，写入目标寄存器的值最终来自内存系统，而不是直接来自源寄存器，因此这打破了从源寄存器携带的依赖关系链。在无条件跳转的情况下，写入目标寄存器的值来自当前的 `pc`（内存模型从不认为它是源寄存器），因此同样，JALR（唯一具有源寄存器的跳转）不携带从 _rs1_ 到 _rd_ 的依赖关系。

[[fflags]]
.(c) 通过 fflags 对 (a) 和 (b) 都有句法依赖，fflags 是 (a) 和 (b) 都隐式累积到的目标寄存器
[.text-center,source%linenums,asm]
----
(a) fadd f3,f1,f2
(b) fadd f6,f4,f5
(c) csrrs a0,fflags,x0
----

累积到目标寄存器而不是写入它的概念反映了 `fflags` 等 CSR 的行为。特别是，累积到寄存器不会覆盖任何先前的写入或累积到同一寄存器。例如，在 <<fflags>> 中，(c) 对 (a) 和 (b) 都有句法依赖。

与其他现代内存模型一样，RVWMO 内存模型使用句法依赖而不是语义依赖。换句话说，这一定义取决于不同指令访问的寄存器的身份，而不是这些寄存器的实际内容。这意味着即使计算似乎可以被“优化掉”，也必须强制执行地址、控制或数据依赖。这一选择确保 RVWMO 仍然与使用这些虚假句法依赖作为轻量级排序机制的代码兼容。

[[address]]
.句法地址依赖
[.text-center, source%linenums, asm]
----
ld a1,0(s0)
xor a2,a1,a1
add s1,s1,a2
ld a5,0(s1)
----

例如，从第一条指令生成的内存操作到最后一条指令生成的内存操作存在句法地址依赖，尽管 `a1` XOR `a1` 为零，因此对第二次加载访问的地址没有影响。

使用依赖作为轻量级同步机制的好处是排序强制要求仅限于特定的两条指令。其他非依赖指令可以由激进的实现自由重新排序。一个替代方案是使用加载获取，但这将强制第一条加载相对于 _所有_ 后续指令的排序。另一个替代方案是使用 FENCE R,R，但这将包括所有先前和所有后续加载，使得这个选项更昂贵。

[[control1]]
.句法控制依赖
[.text-center, source%linenums, asm]
----
lw x1,0(x2)
bne x1,x0,next
sw x3,0(x4)
next: sw x5,0(x6)
----

控制依赖与地址和数据依赖的行为不同，因为控制依赖总是扩展到程序顺序中原始目标之后的所有指令。考虑 <<control1>>，`next` 处的指令将始终执行，但最后一条指令生成的内存操作仍然对第一条指令生成的内存操作有控制依赖。

[[control2]]
.另一个句法控制依赖
[.text-center,source%linenums,asm]
----
lw x1,0(x2)
bne x1,x0,next
next: sw x3,0(x4)
----

同样，考虑 <<control2>>。即使两个分支结果具有相同的目标，从这个片段中的第一条指令生成的内存操作到最后一条指令生成的内存操作仍然存在控制依赖。这一定义的控制依赖比在其他上下文（例如 C++）中看到的稍强，但它符合文献中控制依赖的标准定义。

值得注意的是，PPO 规则 <<overlapping-ordering, 9-11>> 也有意设计为尊重从成功的条件存储指令输出开始的依赖关系。通常，SC 指令后面会跟一个条件分支检查结果是否成功；这意味着从 SC 指令生成的存储操作到分支后面的任何内存操作都有控制依赖。PPO 规则 <<ppo, 11>> 反过来意味着任何后续存储操作将在全局内存顺序中出现在 SC 生成的存储操作之后。然而，由于控制、地址和数据依赖是定义在内存操作上的，并且由于不成功的 SC 不生成内存操作，因此不强制执行不成功的 SC 与其依赖指令之间的顺序。此外，由于 SC 定义为仅在 SC 成功时从其源寄存器携带依赖到 _rd_，因此不成功的 SC 对全局内存顺序没有影响。

[[litmus_lb_lrsc]]
.LB 试纸测试的一个变体（结果禁止）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<",float="center",align="center"]
!===
4+!初始值：0(s0)=1；0(s1)=1
4+!
2+^!Hart 0 2+^!Hart 1 
!(a) !ld a0,0(s0) !(e) !ld a3,0(s2)
!(b) !lr a1,0(s1) !(f) !sd a3,0(s0)
!(c) !sc a2,a0,0(s1) ! !
!(d) !sd a2,0(s2) ! !
4+!结果：`a0=0`，`a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_lb_lrsc.txt[]
a! image::graphviz/litmus_lb_lrsc.png[]
!===
|===

此外，选择尊重从条件存储指令开始的依赖关系确保了某些类似于凭空出现的行为将被防止。考虑 <<litmus_lb_lrsc>>。假设一个假设的实现偶尔可以提前保证条件存储操作将成功。在这种情况下，(c) 可以提前返回 0 给 `a2`（在实际执行之前），允许序列 (d)、(e)、(f)、(a) 和 (b) 执行，然后 (c) 可能仅在那时执行（成功）。这将意味着 (c) 将其自己的成功值写入 `0(s1)`！幸运的是，这种情况和类似的情况通过 RVWMO 尊重从成功的 SC 指令生成的存储开始的依赖关系得以防止。

我们还注意到，指令之间的句法依赖只有在它们以句法地址、控制和/或数据依赖的形式出现时才有任何作用。例如：通过 <<source-dest-regs>> 中的一个“累积 CSR”在两个 `F` 指令之间的句法依赖 _不_ 意味着这两个 `F` 指令必须按顺序执行。这样的依赖只会最终设置一个从两个 `F` 指令到稍后访问 CSR 标志的 CSR 指令的依赖。

[[memory-ppopipeline]]
==== 流水线依赖（<<overlapping-ordering, 规则 12-13>>）

[[addrdatarfi]]
[IMPORTANT]
====
<<overlapping-ordering, 规则 12>>：b 是一个加载指令，并且在程序顺序中 a 和 b 之间存在某个存储 m，m 对 a 有地址或数据依赖，并且 b 返回 m 写入的值

<<overlapping-ordering, 规则 13>>：b 是一个存储指令，并且在程序顺序中 a 和 b 之间存在某个指令 m，m 对 a 有地址依赖
====

[[litmus_datarfi]]
.由于 PPO <<overlapping-ordering, 规则 12>> 和 (d) 到 (e) 的数据依赖，(d) 也必须在全局内存顺序中先于 (f)（结果禁止）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
!===
2+!硬件线程 0 2+! 硬件线程 1
! !li t1, 1 !(d) !lw a0, 0(s1)
!(a) !sw t1,0(s0) !(e) !sw a0, 0(s2)
!(b) !fence w, w !(f) !lw a1, 0(s2)
!(c) !sw t1,0(s1) ! !xor a2,a1,a1
! ! ! !add s0,s0,a2
! ! !(g) !lw a3,0(s0)
4+!结果：`a0=1`，`a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_datarfi.txt[]
a! image::graphviz/litmus_datarfi.png[]
!===
|===

PPO 规则 <<overlapping-ordering, 12>> 和 <<overlapping-ordering, 13>> 反映了几乎所有实际处理器流水线实现的行为。规则 <<overlapping-ordering, 12>> 规定加载不能从存储转发，直到该存储的地址和数据已知。考虑 <<litmus_datarfi>> (f) 不能执行，直到 (e) 的数据已解析，因为 (f) 必须返回 (e) 写入的值（或全局内存顺序中更晚的值），并且在 (d) 执行之前，(e) 的写回不能覆盖旧值。因此，(f) 永远不会在 (d) 执行之前执行。

.由于 (e) 和 (g) 之间的额外存储，(d) 不再需要先于 (g)（结果允许）

[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<",float="center",align="center",options="header",]
!===
2+!Hart 0 2+!Hart 1
2+!li t1, 1 2+^!li t1, 1
!(a) !sw t1,0(s0) !(d) !lw a0, 0(s1)
!(b) !fence w, w !(e) !sw a0, 0(s2)
!(c) !sw t1,0(s1) !(f) !sw t1, 0(s2)
! ! !(g) !lw a1, 0(s2)
! ! ! !xor a2,a1,a1
! ! ! !add s0,s0,a2
! ! !(h) !lw a3,0(s0)
4+!Outcome: `a0=1`, `a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_datacoirfi.txt[]
a! image::graphviz/litmus_datacoirfi.png[]
!===
|===

如果在 (e) 和 (f) 之间有另一个对相同地址的存储，如 <<litmus:addrdatarfi_no>> 中所示，那么 (f) 将不再依赖于 (e) 的数据解析，因此 (f) 对 (d) 的依赖将被打破，(d) 生成 (e) 的数据。

规则 <<overlapping-ordering, 13>> 对前一规则做了类似的观察：存储不能在内存中执行，直到所有可能访问相同地址的先前加载都已执行。这样的加载必须在存储之前执行，但如果存储在加载有机会读取旧值之前覆盖了内存中的值，则加载不能这样做。同样，存储通常不能执行，直到知道前面的指令不会因地址解析失败而导致异常，从这个意义上说，规则 13 可以看作是规则 <<overlapping-ordering, 11>> 的一个特例。

[[litmus:addrdatarfi_no]]
.由于 (d) 到 (e) 的地址依赖，(d) 也先于 (f)（结果禁止）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<"float="center",align="center",options="header"]
!===
2+!硬件线程 0 2+^!硬件线程 1
2+! 2+^!li t1, 1
!(a) !lw a0,0(s0) !(d) !lw a1, 0(s1)
!(b) !fence rw,rw !(e) !lw a2, 0(a1)
!(c) !sw s2,0(s1) !(f) !sw t1, 0(s0)
4+!结果：`a0=1`，`a1=t`
!===
|
!===
//a! graphviz::images/graphviz/litmus_addrpo.txt[]
a! image:graphviz/litmus_addrpo.png[]
!===
|===

考虑 <<litmus:addrdatarfi_no>> (f) 不能执行，直到 (e) 的地址解析，因为地址可能匹配；即 `a1=s0`。因此，在 (d) 执行并确认地址确实重叠之前，(f) 不能发送到内存。

=== 超越主内存

RVWMO 目前不尝试正式描述 FENCE.I、SFENCE.VMA、I/O 栅栏和 PMA 的行为。所有这些行为将在未来的形式化中描述。与此同时，FENCE.I 的行为在 <<zifencei>> 中描述，SFENCE.VMA 的行为在 RISC-V 指令集特权架构手册中描述，I/O 栅栏和 PMA 的行为如下所述。

==== 一致性和可缓存性

RISC-V 特权 ISA 定义了物理内存属性（PMA），其中指定了地址空间的某些部分是否一致和/或可缓存。有关完整详细信息，请参阅 RISC-V 特权 ISA 规范。这里，我们仅讨论每个 PMA 中的各种详细信息如何与内存模型相关：

* 主内存与 I/O 以及 I/O 内存排序 PMA：定义的内存模型适用于主内存区域。I/O 排序如下所述。
* 支持的访问类型和原子性 PMA：内存模型仅在每个区域支持的原语之上应用。
* 可缓存性 PMA：一般来说，可缓存性 PMA 不影响内存模型。非缓存区域的行为可能比缓存区域更严格，但无论如何，允许的行为集不会改变。然而，一些平台特定和/或设备特定的可缓存性设置可能会有所不同。
* 一致性 PMA：标记为非一致性的内存区域的内存一致性模型目前是平台特定和/或设备特定的：加载值公理、原子性公理和进展公理都可能被非一致性内存违反。然而，一致性内存不需要硬件缓存一致性协议。RISC-V 特权 ISA 规范建议不鼓励硬件非一致性区域的主内存，但内存模型与硬件一致性、软件一致性、由于只读内存而隐含的一致性、由于只有一个代理访问而隐含的一致性或其他方式兼容。
* 幂等性 PMA：幂等性 PMA 用于指定加载和/或存储可能具有副作用的内存区域，这反过来用于微架构确定，例如，预取是否合法。这一区别不影响内存模型。

==== I/O 排序

对于 I/O，加载值公理和原子性公理通常不适用，因为读取和写入可能具有设备特定的副作用，并且可能返回与最近存储到相同地址的值不同的值。然而，以下保留程序顺序规则通常仍适用于对 I/O 内存的访问：如果 _a_ 在程序顺序中先于 _b_，并且以下之一成立，则 _a_ 在全局内存顺序中先于 _b_：

. _a_ 在保留程序顺序中先于 _b_，如 <<memorymodel>> 中定义，获取和释放排序注释仅适用于从一个内存操作到另一个内存操作以及从一个 I/O 操作到另一个 I/O 操作，但不适用于从内存操作到 I/O 操作或反之亦然
. _a_ 和 _b_ 是对 I/O 区域重叠地址的访问
. _a_ 和 _b_ 是对相同强排序 I/O 区域的访问
. _a_ 和 _b_ 是对 I/O 区域的访问，并且与 _a_ 或 _b_ 访问的 I/O 区域相关的通道是通道 1
. _a_ 和 _b_ 是对与相同通道（除通道 0 外）相关的 I/O 区域的访问

请注意，FENCE 指令在其前驱集和后继集中区分主内存操作和 I/O 操作。要强制 I/O 操作和主内存操作之间的排序，代码必须使用带有 PI、PO、SI 和/或 SO 以及 PR、PW、SR 和/或 SW 的 FENCE。例如，要强制主内存写入和设备寄存器的 I/O 写入之间的排序，需要 FENCE W,O 或更强的排序。
[[wo]]
.排序内存和 I/O 访问
[.text-center,source%linenums,asm]
----
sd t0, 0(a0)
fence w,o 
sd a0, 0(a1)
----

当实际使用栅栏时，实现必须假设设备可能在接收到 MMIO 信号后立即尝试访问内存，并且该设备对内存的后续内存访问必须观察到所有在该 MMIO 操作之前排序的访问的效果。换句话说，在 <<wo>> 中，假设 `0(a0)` 在主内存中，`0(a1)` 是 I/O 内存中设备寄存器的地址。如果设备在接收到 MMIO 写入后访问 `0(a0)`，则根据 RVWMO 内存模型的规则，该加载必须概念上出现在第一次存储到 `0(a0)` 之后。在某些实现中，确保这一点的唯一方法是要求第一次存储在发出 MMIO 写入之前实际完成。其他实现可能会找到更积极的方法，而其他实现可能根本不需要对 I/O 和主内存访问做任何不同的事情。然而，RVWMO 内存模型不区分这些选项；它只是提供了一种与实现无关的机制来指定必须强制执行的排序。

许多架构包括“排序”和“完成”栅栏的单独概念，特别是与 I/O（与常规主内存相对）相关。排序栅栏仅确保内存操作保持顺序，而完成栅栏确保前驱访问在任何后继可见之前都已完成。RISC-V 没有明确区分排序和完成栅栏。相反，这种区别只是从 FENCE 位的不同使用中推断出来的。

对于符合 RISC-V Unix 平台规范的实现，I/O 设备和 DMA 操作需要一致地访问内存并通过强排序 I/O 通道。因此，同时由外部设备访问的常规主内存区域的访问也可以使用标准同步机制。不符合 Unix 平台规范和/或设备不一致访问内存的实现将需要使用机制（目前是平台特定或设备特定的）来强制一致性。

地址空间中的 I/O 区域应被视为这些区域的 PMA 中的非缓存区域。如果这些区域不被任何代理缓存，则可以通过 PMA 视为一致的。

本节中的排序保证可能不适用于 RISC-V 内核和设备之间的平台特定边界之外。特别是，通过外部总线（例如 PCIe）发送的 I/O 访问可能在到达最终目的地之前重新排序。在这种情况下，必须根据这些外部设备和总线的平台特定规则强制执行排序。

[[memory_porting]]
=== 代码移植和映射指南

[[tsomappings]]
.TSO 操作到 RISC-V 操作的映射
[%autowidth,float="center", align="center",cols="<,<",options="header",separator=!]
|===
!x86/TSO 操作 !RVWMO 映射
!加载 ! `l{b|h|w|d}; fence r,rw`
!存储 !`fence rw,w; s{b|h|w|d}`
!原子 RMW !`amo<op>.{w|d}.aqrl OR` +
`loop:lr.{w|d}.aq; <op>; sc.{w|d}.aqrl; bnez loop`
!栅栏 !`fence rw,rw`
|===

<<tsomappings>> 提供了 TSO 内存操作到 RISC-V 内存指令的映射。正常的 x86 加载和存储本质上都是获取-RCpc 和释放-RCpc 操作：TSO 默认强制所有加载-加载、加载-存储和存储-存储排序。因此，在 RVWMO 下，所有 TSO 加载必须映射到加载后跟 FENCE R,RW，所有 TSO 存储必须映射到 FENCE RW,W 后跟存储。TSO 原子读-修改-写和使用 LOCK 前缀的 x86 指令是完全排序的，可以通过设置 _aq_ 和 _rl_ 的 AMO 实现，或者通过设置 _aq_ 的 LR、相关的算术操作、设置 _aq_ 和 _rl_ 的 SC 以及检查成功条件的条件分支实现。在后一种情况下，LR 上的 _rl_ 注释实际上是多余的，可以省略。

<<tsomappings>> 的替代方案也是可能的。TSO 存储可以映射到设置 _rl_ 的 AMOSWAP。然而，由于 RVWMO PPO 规则 <<overlapping-ordering, 3>> 禁止将值从 AMO 转发到后续加载，使用 AMOSWAP 进行存储可能会对性能产生负面影响。TSO 加载可以使用设置 _aq_ 的 LR 进行映射：所有此类 LR 指令将是未配对的，但这一事实本身并不排除使用 LR 进行加载。然而，再次，这种映射可能会对性能产生负面影响，如果它对保留机制施加的压力超过了最初的预期。

[[powermappings]]
.Power 操作到 RISC-V 操作的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!Power 操作 !RVWMO 映射
!加载 !`l{b|h|w|d}`
!加载-保留 !`lr.{w|d}`
!存储 !`s{b|h|w|d}`
!存储-条件 !`sc.{w|d}`
!`lwsync` !`fence.tso`
!`sync` !`fence rw,rw`
!`isync` !`fence.i; fence r,r`
|===

<<powermappings>> 提供了 Power 内存操作到 RISC-V 内存指令的映射。Power ISYNC 在 RISC-V 上映射到 FENCE.I 后跟 FENCE R,R；后者的栅栏是必需的，因为 ISYNC 用于定义 RVWMO 中不存在的“控制+控制栅栏”依赖关系。

[[armmappings]]
.从ARM操作到RISC-V操作的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!ARM 操作 !RVWMO 映射
!Load !`l{b|h|w|d}`
!Load-Acquire !`fence rw, rw; l{b|h|w|d}; fence r,rw`
!Load-Exclusive !`lr.{w|d}`
!Load-Acquire-Exclusive !`lr.{w|d}.aqrl`
!Store !`s{b|h|w|d}`
!Store-Release !`fence rw,w; s{b|h|w|d}`
!Store-Exclusive !`sc.{w|d}`
!Store-Release-Exclusive !`sc.{w|d}.rl`
!`dmb` !`fence rw,rw`
!`dmb.ld` !`fence r,rw`
!`dmb.st` !`fence w,w`
!`isb` !`fence.i; fence r,r`
|===

<<armmappings>> 提供了从ARM内存操作到RISC-V内存指令的映射。由于RISC-V目前没有带有 _aq_ 或 _rl_ 注释的普通加载和存储操作码，ARM的加载-获取和存储-释放操作应使用fence来映射。此外，为了强制存储-释放到加载-获取的顺序，在存储-释放和加载-获取之间必须有一个FENCE RW,RW；<<armmappings>> 通过在每个获取操作前始终放置fence来强制执行这一点。ARM的加载-独占和存储-独占指令同样可以映射到它们的RISC-V LR和SC等价物，但我们不在带有 _aq_ 设置的LR前放置FENCE RW,RW，而是简单地也设置 _rl_。ARM的ISB在RISC-V上映射为FENCE.I，然后是FENCE R,R，类似于Power的ISYNC映射。

[[linuxmappings]]
.从Linux内存原语到RISC-V原语的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!Linux 操作 !RVWMO 映射

!`smp_mb()` !`fence rw,rw`

!`smp_rmb()` !`fence r,r`

!`smp_wmb()` !`fence w,w`

!`dma_rmb()` !`fence r,r`

!`dma_wmb()` !`fence w,w`

!`mb()` !`fence iorw,iorw`

!`rmb()` !`fence ri,ri`

!`wmb()` !`fence wo,wo`

!`smp_load_acquire()` !`l{b|h|w|d}; fence r,rw`

!`smp_store_release()` !`fence.tso; s{b|h|w|d}`

!Linux 构造 !RVWMO AMO 映射

!`atomic &#60;op&#62; relaxed` !`amo &#60;op&#62;.{w|d}`

!`atomic &#60;op&#62; acquire` !`amo &#60;op&#62;.{w|d}.aq`

!`atomic &#60;op&#62; release` !`amo &#60;op&#62;.{w|d}.rl`

!`atomic &#60;op&#62;` !`amo &#60;op&#62;.{w|d}.aqrl`

!Linux 构造 !RVWMO LR/SC 映射

!`atomic &#60;op&#62; relaxed` !`loop:lr.{w|d}; &#60;op&#62;; sc.{w|d}; bnez loop`

!`atomic &#60;op&#62; acquire` !`loop:lr.{w|d}.aq; &#60;op&#62;; sc.{w|d}; bnez loop`

!`atomic &#60;op&#62; release` !`loop:lr.{w|d}; &#60;op&#62;; sc.{w|d}.aqrl^&#42;; bnez loop OR`

! !`fence.tso; loop:lr.{w|d}; &#60;op &#62;; sc.{w|d}^&#42;; bnez loop`

!`atomic &#60;op&#62;` !`loop:lr.{w|d}.aq;` `&#60;op&#62;; sc.{w|d}.aqrl; bnez loop`

|===

关于<<linuxmappings>>，其他构造（如自旋锁）应相应遵循。具有非一致性DMA的平台或设备可能需要额外的同步（如缓存刷新或失效机制）；目前任何此类额外的同步将是设备特定的。

<<linuxmappings>> 提供了Linux内存排序宏到RISC-V内存指令的映射。Linux的fence `dma_rmb()` 和 `dma_wmb()` 映射到FENCE R,R和FENCE W,W，因为RISC-V Unix平台要求一致性DMA，但在具有非一致性DMA的平台上将映射到FENCE RI,RI和FENCE WO,WO。具有非一致性DMA的平台还可能需要一种机制来刷新和/或失效缓存行。这些机制将是设备特定的和/或在未来的ISA扩展中标准化。

Linux的释放操作映射可能看起来比必要的更强，但这些映射是为了涵盖一些Linux需要比更直观的映射提供更强顺序的情况。特别是，在撰写本文时，Linux正在积极讨论是否要求在一个关键区中的访问和同一hart中由相同同步对象保护的后续关键区中的访问之间的加载-加载、加载-存储和存储-存储顺序。并非所有FENCE RW,W/FENCE R,RW映射与 _aq_/_rl_ 映射的组合都能提供这样的顺序。有几种解决这个问题的方法，包括：

. 始终使用FENCE RW,W/FENCE R,RW，从不使用 _aq_/_rl_。这足够了，但不理想，因为它破坏了 _aq_/_rl_ 修饰符的目的。
. 始终使用 _aq_/_rl_，从不使用FENCE RW,W/FENCE R,RW。这目前不起作用，因为缺少带有 _aq_ 和 _rl_ 修饰符的加载和存储操作码。
. 加强释放操作的映射，使其在存在任何类型的获取映射时强制执行足够的顺序。这是目前推荐的解决方案，也是<<linuxmappings>>中显示的解决方案。

RVWMO 映射: (a) lw a0, 0(s0) (b) fence.tso // vs. fence rw,w (c) sd x0,0(s1) ... loop: (d) amoswap.d.aq a1,t1,0(s1) bnez a1,loop (e) lw a2,0(s2)

例如，Linux社区目前正在讨论的关键区顺序规则将要求(a)在<<lkmm_ll>>中被排序在(e)之前。如果确实需要这样，那么(b)映射为FENCE RW,W将是不够的。也就是说，这些映射可能会随着Linux内核内存模型的发展而改变。

[[lkmm_ll]]
.Linux中关键区之间的顺序
[source%linenums,asm]
----
Linux代码:
(a) int r0 = *x;
       (bc) spin_unlock(y, 0);
....
....
(d) spin_lock(y);
(e) int r1 = *z;

RVWMO 映射:
(a) lw a0, 0(s0)
(b) fence.tso // vs. fence rw,w
(c) sd x0,0(s1)
....
loop:
(d) amoswap.d.aq a1,t1,0(s1)
bnez a1,loop
(e) lw a2,0(s2)
----

<<c11mappings>> 提供了C11/C++11原子操作到RISC-V内存指令的映射。如果引入带有 _aq_ 和 _rl_ 修饰符的加载和存储操作码，那么<<c11mappings_hypothetical>>中的映射将足够。然而请注意，只有当`atomic_<op>(memory_order_seq_cst)`使用同时设置了 _aq_ 和 _rl_ 的LR进行映射时，这两种映射才能正确互操作。
更重要的是，<<c11mappings>>中的顺序一致存储，后跟<<c11mappings_hypothetical>>中的顺序一致加载，除非通过添加第二个fence或将存储映射到`amoswap.rl`来加强<<c11mappings>>中的存储映射，否则可以重新排序。

[[c11mappings]]
.从C/C++原语到RISC-V原语的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===

!C/C++ 构造 !RVWMO 映射

!非原子加载 !`l{b|h|w|d}`

!`atomic_load(memory_order_relaxed)` !`l{b|h|w|d}`

!`atomic_load(memory_order_acquire)` !`l{b|h|w|d}; fence r,rw`

!`atomic_load(memory_order_seq_cst)` !`fence rw,rw; l{b|h|w|d}; fence r,rw`

!非原子存储 !`s{b|h|w|d}`

!`atomic_store(memory_order_relaxed)` !`s{b|h|w|d}`

!`atomic_store(memory_order_release)` !`fence rw,w; s{b|h|w|d}`

!`atomic_store(memory_order_seq_cst)` !`fence rw,w; s{b|h|w|d}`

!`atomic_thread_fence(memory_order_acquire)` !`fence r,rw`

!`atomic_thread_fence(memory_order_release)` !`fence rw,w`

!`atomic_thread_fence(memory_order_acq_rel)` !`fence.tso`

!`atomic_thread_fence(memory_order_seq_cst)` !`fence rw,rw`

!C/C++ 构造 !RVWMO AMO 映射

!`atomic_<op>(memory_order_relaxed)` !`amo<op>.{w|d}`

!`atomic_<op>(memory_order_acquire)` !`amo<op>.{w|d}.aq`

!`atomic_<op>(memory_order_release)` !`amo<op>.{w|d}.rl`

!`atomic_<op>(memory_order_acq_rel)` !`amo<op>.{w|d}.aqrl`

!`atomic_<op>(memory_order_seq_cst)` !`amo<op>.{w|d}.aqrl`

!C/C++ 构造 !RVWMO LR/SC 映射

!`atomic_<op>(memory_order_relaxed)` !`loop:lr.{w|d}; <op>; sc.{w|d};`

! !`bnez loop`

!`atomic_<op>(memory_order_acquire)` !`loop:lr.{w|d}.aq; <op>; sc.{w|d};`

! !`bnez loop`

!`atomic_<op>(memory_order_release)` !`loop:lr.{w|d}; <op>; sc.{w|d}.rl;`

! !`bnez loop`

!`atomic_<op>(memory_order_acq_rel)` !`loop:lr.{w|d}.aq; <op>; sc.{w|d}.rl;`

! !`bnez loop`

!`atomic_<op>(memory_order_seq_cst)` !`loop:lr.{w|d}.aqrl; <op>;`

! !`sc.{w|d}.rl; bnez loop`

|===

[[c11mappings_hypothetical]]
.假设引入本地加载-获取和存储-释放操作码时，从C/C++原语到RISC-V原语的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!C/C++ 构造 !RVWMO 映射

!非原子加载 !`l{b|h|w|d}`

!`atomic_load(memory_order_relaxed)` !`l{b|h|w|d}`

!`atomic_load(memory_order_acquire)` !`l{b|h|w|d}.aq`

!`atomic_load(memory_order_seq_cst)` !`l{b|h|w|d}.aq`

!非原子存储 !`s{b|h|w|d}`

!`atomic_store(memory_order_relaxed)` !`s{b|h|w|d}`

!`atomic_store(memory_order_release)` !`s{b|h|w|d}.rl`

!`atomic_store(memory_order_seq_cst)` !`s{b|h|w|d}.rl`

!`atomic_thread_fence(memory_order_acquire)` !`fence r,rw`

!`atomic_thread_fence(memory_order_release)` !`fence rw,w`

!`atomic_thread_fence(memory_order_acq_rel)` !`fence.tso`

!`atomic_thread_fence(memory_order_seq_cst)` !`fence rw,rw`

!C/C++ 构造 !RVWMO AMO 映射

!`atomic_<op>(memory_order_relaxed)` !`amo<op>.{w|d}`

!`atomic_<op>(memory_order_acquire)` !`amo<op>.{w|d}.aq`

!`atomic_<op>(memory_order_release)` !`amo<op>.{w|d}.rl`

!`atomic_<op>(memory_order_acq_rel)` !`amo<op>.{w|d}.aqrl`

!`atomic_<op>(memory_order_seq_cst)` !`amo<op>.{w|d}.aqrl`

!C/C++ 构造 !RVWMO LR/SC 映射

!`atomic_<op>(memory_order_relaxed)` !`lr.{w|d}; <op>; sc.{w|d}`

!`atomic_<op>(memory_order_acquire)` !`lr.{w|d}.aq; <op>; sc.{w|d}`

!`atomic_<op>(memory_order_release)` !`lr.{w|d}; <op>; sc.{w|d}.rl`

!`atomic_<op>(memory_order_acq_rel)` !`lr.{w|d}.aq; <op>; sc.{w|d}.rl`

!`atomic_<op>(memory_order_seq_cst)` !`lr.{w|d}.aq* <op>; sc.{w|d}.rl`

2+!`*` 必须是 `lr.{w|d}.aqrl` 以便与按<<c11mappings>>映射的代码互操作
|===

任何AMO都可以通过LR/SC对来模拟，但必须注意确保从LR开始的任何PPO顺序也从SC开始，并且在SC结束的任何PPO顺序也在LR结束。例如，LR还必须尊重AMO的任何数据依赖性，因为加载操作本身没有数据依赖性的概念。同样，必须使同一hart中其他地方的FENCE R,R的效果也适用于SC，否则SC不会尊重该fence。模拟器可以通过简单地将AMO映射到`lr.aq; <op>; sc.aqrl`来实现这一效果，这与其他地方用于完全有序原子的映射相匹配。

这些C11/C++11映射要求平台为所有内存提供以下物理内存属性（如RISC-V特权ISA中定义）：

* 主内存
* 一致性
* AMOArithmetic
* RsrvEventual

具有不同属性的平台可能需要不同的映射，或需要特定平台的软件（例如，内存映射I/O）。

=== 实现指南

RVWMO和RVTSO内存模型绝不排除微架构采用复杂的推测技术或其他形式的优化以提供更高的性能。这些模型也不要求使用任何特定的缓存层次结构，甚至不要求使用缓存一致性协议。相反，这些模型只指定可以暴露给软件的行为。微架构可以自由使用任何流水线设计、任何一致或非一致的缓存层次结构、任何片上互连等，只要设计只允许满足内存模型规则的执行。也就是说，为了帮助人们理解内存模型的实际实现，在本节中我们提供了一些关于架构师和程序员如何解释模型规则的指南。

RVWMO和RVTSO都是多副本原子（或其他多副本原子）：任何对发出它的hart以外的hart可见的存储值也必须在概念上对系统中的所有其他hart可见。换句话说，hart可以在其自己的先前存储变得对所有hart全局可见之前从其自己的先前存储中转发，但不允许早期的hart间转发。多副本原子性可以通过多种方式强制执行。它可能由于缓存和存储缓冲区的物理设计而固有地存在，可能通过单写入者/多读取者缓存一致性协议强制执行，或者可能由于其他机制而存在。

尽管多副本原子性确实对微架构施加了一些限制，但它是使内存模型不变得极其复杂的关键属性之一。例如，hart不能合法地从邻近hart的私有存储缓冲区转发一个值（除非当然是以不会使任何新的非法行为在架构上可见的方式进行）。缓存一致性协议也不能在协议使其他缓存中的所有旧副本失效之前将一个值从一个hart转发到另一个hart。当然，微架构可以（并且高性能实现可能会）通过推测或其他优化在幕后违反这些规则，只要任何不合规的行为不暴露给程序员。

作为解释RVWMO中PPO规则的粗略指南，我们期望从软件角度来看：

* 程序员将定期和积极地使用PPO规则<<overlapping-ordering, 1>>和<<overlapping-ordering, 4-8>>。
* 专家程序员将使用PPO规则<<overlapping-ordering, 9-11>>来加速重要数据结构的关键路径。
* 即使是专家程序员也很少或从不直接使用PPO规则<<overlapping-ordering, 2-3>>和<<overlapping-ordering, 12-13>>。
这些规则包括在内是为了促进常见的微架构优化（规则<<overlapping-ordering, 2>>）和描述的操作形式建模方法（规则<<overlapping-ordering, 3>>和<<overlapping-ordering, 12-13>>）<<operational>>。它们还促进了从具有类似规则的其他架构移植代码的过程。

我们还期望从硬件角度来看：

* PPO规则<<overlapping-ordering, 1>>和<<overlapping-ordering, 3-6>>反映了应该对架构师几乎没有惊喜的规则。
* PPO规则<<overlapping-ordering, 2>>反映了一种自然且常见的硬件优化，但这种优化非常微妙，因此值得仔细检查。
* PPO规则<<overlapping-ordering, 7>>可能对架构师来说并不立即明显，但它是标准的内存模型要求。
* 加载值公理、原子性公理和PPO规则<<overlapping-ordering, 8-13>>反映了大多数硬件实现自然会强制执行的规则，除非它们包含极端优化。当然，实现仍应确保仔细检查这些规则。硬件还必须确保语法依赖性不会被“优化掉”。

架构可以自由地以他们选择的任何保守方式实现任何内存模型规则。例如，硬件实现可以选择执行以下任何或所有操作：

* 将所有fence解释为FENCE RW,RW（如果涉及I/O，则为FENCE IORW,IORW），无论实际设置了哪些位
* 将所有带有PW和SR的fence实现为FENCE RW,RW（如果涉及I/O，则为FENCE IORW,IORW），因为PW和SR是四种可能的主内存排序组件中最昂贵的
* 按<<memory_porting>>中描述的方式模拟 _aq_ 和 _rl_
* 强制执行所有相同地址的加载-加载排序，即使存在诸如`fri-rfi`和`RSW`的模式
* 禁止从存储缓冲区中的存储值转发到同一地址的后续AMO或LR
* 禁止从存储缓冲区中的AMO或SC值转发到同一地址的后续加载
* 在所有内存访问上实现TSO，并忽略不包括PW和SR排序的任何主内存fence（例如，Ztso实现将这样做）
* 将所有原子操作实现为RCsc甚至完全有序，无论注释如何

实现RVTSO的架构可以安全地执行以下操作：

* 忽略所有不同时具有PW和SR的fence（除非fence还对I/O排序）
* 忽略除规则<<overlapping-ordering, 4>>到<<overlapping-ordering, 7>>之外的所有PPO规则，因为在RVTSO假设下其余规则与其他PPO规则冗余

其他一般说明：

* 静默存储（即，写入与内存位置中已存在的值相同的存储）从内存模型的角度来看与任何其他存储行为相同。同样，实际上不改变内存中值的AMO（例如，AMOMAX，其中_rs2_中的值小于内存中当前的值）在语义上仍被视为存储操作。尝试实现静默存储的微架构必须注意确保仍然遵守内存模型，特别是在诸如RSW <<mm-overlap>>的情况下，这些情况往往与静默存储不兼容。
* 写入可以合并（即，对同一地址的两个连续写入可以合并）或替代（即，对同一地址的两个背靠背写入中的较早一个可以省略），只要结果行为不以其他方式违反内存模型语义。

可以通过以下示例理解写入替代的问题：

.写入替代试验，允许的执行
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
!===
2+!Hart 0 2+^!Hart 1
2+!li t1, 3 2+^!li t3, 2
! !li t2, 1 ! !
!(a) !sw t1,0(s0) !(d) !lw a0,0(s1)
!(b) !fence w, w !(e) !sw a0,0(s0)
!(c) !sw t2,0(s1) !(f) !sw t3,0(s0)
!===
|
!===
//a! graphviz::images/graphviz/litmus_subsumption.txt[]
a! image::graphviz/litmus_subsumption.png[]
!===
|===

如所写，如果加载(d)读取值_1_，则(a)必须在全局内存顺序中先于(f)：

* (a)在全局内存顺序中先于(c)，因为规则2
* (c)在全局内存顺序中先于(d)，因为加载值公理
* (d)在全局内存顺序中先于(e)，因为规则7
* (e)在全局内存顺序中先于(f)，因为规则1

换句话说，地址在`s0`中的内存位置的最终值必须是_2_（由存储(f)写入的值），而不能是_3_（由存储(a)写入的值）。

一个非常激进的微架构可能会错误地决定丢弃(e)，因为(f)取代了它，这可能会导致微架构破坏(d)和(f)之间的现在已消除的依赖关系（因此也破坏(a)和(f)之间的依赖关系）。这将违反内存模型规则，因此是被禁止的。在其他情况下，如果例如(d)和(e)之间没有数据依赖性，写入替代可能是合法的。

==== 可能的未来扩展

我们预计以下任何或所有可能的未来扩展都将与RVWMO内存模型兼容：

* "V" 向量ISA扩展
* "J" JIT扩展
* 带有 _aq_ 和 _rl_ 设置的加载和存储操作码的本地编码
* 限制到某些地址的fence
* 缓存写回/刷新/失效等指令

[[discrepancies]]
=== 已知问题

[[mixedrsw]]
==== 混合大小RSW

[[rsw1]]
.混合大小差异（公理模型允许，操作模型禁止）
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
|===
2+|Hart 0 2+^|Hart 1
2+|li t1, 1 2+^|li t1, 1
|(a) |lw a0,0(s0) |(d) |lw a1,0(s1)
|(b) |fence rw,rw |(e) |amoswap.w.rl a2,t1,0(s2)
|(c) |sw t1,0(s1) |(f) |ld a3,0(s2)
| | |(g) |lw a4,4(s2)
| | | |xor a5,a4,a4
| | | |add s0,s0,a5
| | |(h) |sw t1,0(s0)
4+|结果：`a0=1`，`a1=1`，`a2=0`，`a3=1`，`a4=0`
|===

[[rsw2]]
.混合大小差异（公理模型允许，操作模型禁止）
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header"]
|===
2+|Hart 0 2+^|Hart 1 
2+|li t1, 1 2+^|li t1, 1
|(a) |lw a0,0(s0) |(d) |ld a1,0(s1)
|(b) |fence rw,rw |(e) |lw a2,4(s1)
|(c) |sw t1,0(s1) | |xor a3,a2,a2
| | | |add s0,s0,a3
| | |(f) |sw t1,0(s0)
4+|结果：`a0=1`，`a1=1`，`a2=0`
|===

[[rsw3]]
.混合大小差异（公理模型允许，操作模型禁止）
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
|===
2+|Hart 0 2+^|Hart 1
2+|li t1, 1 2+^|li t1, 1
|(a) |lw a0,0(s0) |(d) |sw t1,4(s1)
|(b) |fence rw,rw |(e) |ld a1,0(s1)
|(c) |sw t1,0(s1) |(f) |lw a2,4(s1)
| | | |xor a3,a2,a2
| | | |add s0,s0,a3
| | |(g) |sw t1,0(s0)
4+|结果：`a0=1`，`a1=0x100000001`，`a2=1`
|===

在<<rsw1>>-<<rsw3>>中显示的混合大小RSW变体家族中，操作规范和公理规范之间存在已知差异。
为了解决这个问题，我们可能会选择添加类似以下的新PPO规则：如果内存操作_a_在保留的程序顺序中先于内存操作_b_（因此也在全局内存顺序中），则_a_在程序顺序中先于_b_，_a_和_b_都访问常规主内存（而不是I/O区域），_a_是加载，_b_是存储，在_a_和_b_之间有一个加载_m_，有一个字节_x_，_a_和_m_都读取该字节，在_a_和_m_之间没有写入_x_的存储，并且_m_在PPO中先于_b_。换句话说，在herd语法中，我们可能会选择将`(po-loc & rsw);ppo;[W]`添加到PPO。许多实现已经自然地强制执行此排序。因此，即使此规则不是官方的，我们仍建议实现者强制执行它，以确保与可能将来将此规则添加到RVWMO的前向兼容性。

