[appendix]
== RVWMO解释材料，版本0.1
[[mm-explain]]

本节通过更通俗的语言和具体的例子进一步解释了 RVWMO 内存模型，目的是帮助读者更好地理解公理和程序顺序规则的含义与意图。本附录为注释性内容；所有规范性材料已在 <<内存模型>> 部分及 ISA 规范的其他章节中提供。已知差异列在 <<差异>> 部分，其他差异为无意之举。

[[whyrvwmo]]
=== 为什么选择 RVWMO？

内存一致性模型从弱到强有着不同的表现。弱一致性模型给予硬件更多的实现自由度，通常在性能、每瓦性能、功耗、可扩展性和硬件验证开销方面优于强一致性模型，但代价是编程模型更为复杂。而强一致性模型则提供简化的编程模型，但限制了流水线和内存系统中可以执行的（非推测性）硬件优化，导致功耗、面积和验证开销的增加。

RISC-V 采用了 RVWMO 内存模型，它是发布一致性的一个变体，位于内存模型范围的中间。RVWMO 使架构师能够设计各种实现，包括简单实现、激进实现、嵌入式实现或其他任何实现方式，同时仍能支持高性能编程语言的内存模型。

为便于其他架构的代码移植，一些硬件实现可能会选择实现 Ztso 扩展，它提供更严格的 RVTSO 顺序语义。针对 RVWMO 编写的代码可以自动兼容 RVTSO，但 RVTSO 编写的代码不能保证在 RVWMO 实现上正确运行。实际上，大多数 RVWMO 实现（且应该）会拒绝运行仅支持 RVTSO 的二进制文件。因此，每个实现必须决定是优先考虑与 RVTSO 代码的兼容性（例如，支持从 x86 移植），还是优先考虑与其他 RVWMO 实现的 RISC-V 核心的兼容性。

在 RVWMO 编写的代码中，某些屏障和内存排序注释在 RVTSO 下可能变得多余。RVWMO 在 Ztso 实现中，默认将这些屏障操作转化为无操作（如 FENCE R,RW 和 FENCE RW,W），从而避免增加额外开销。但如果需要兼容非 Ztso 实现，这些屏障操作必须保留。

[[litmustests]]
=== 试纸测试

本章的解释采用了试纸测试，即一段小型程序，旨在测试或突出内存模型的某个特定方面。<<litmus-sample>> 展示了一个包含两个硬件线程的试纸测试示例。对于该图及本章接下来的所有图，我们假设 `s0`、`s1` 和 `s2` 在所有硬件线程中预设为相同的值，其中 `s0` 保存地址 x，`s1` 保存地址 y，`s2` 保存地址 z，且 x、y 和 z 是对齐到 8 字节边界的不重叠内存位置。其他寄存器和所有引用的内存位置均初始化为零。每个图的左侧展示试纸测试代码，右侧则为该测试的有效或无效执行的可视化结果。

[[litmus-sample, 试纸测试示例]]
[float="center",align="center",cols="1a,.^1a",frame="none",grid="none",options="noheader"]
.一个简单的试纸测试及一个无效执行 (`a0=1`).
|===
|
[.left]
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header"]
!===
2+!Hart 0 2+!Hart 1 
! !&#8942; ! !&#8942;
! !li t1,1 ! !li t4,4
!(a) !sw t1,0(s0) !(e) !sw t4,0(s0)
! !&#8942; ! !&#8942;
! !li t2,2 ! !
!(b) !sw t2,0(s0) ! !
! !&#8942; ! !&#8942;
!(c) !lw a0,0(s0) ! !
! !&#8942; ! !&#8942;
! !li t3,3 ! !li t5,5
!(d) !sw t3,0(s0) !(f) !sw t5,0(s0)
! !&#8942; ! !&#8942;
!===
|
!===
//a! graphviz::images/graphviz/litmus_sample.txt[]
a! image::graphviz/litmus_sample.png[]
!===
|===

试纸测试用于分析内存模型在特定情境下的表现。例如，在 <<litmus-sample>> 中，第一硬件线程上 `a0` 的最终值可能为 2、4 或 5，具体取决于每个硬件线程的指令流在运行时的交错情况。然而，在这个例子中，第一硬件线程上 `a0` 的最终值永远不会是 1 或 3；直观地讲，值 1 在加载指令执行时已经不可见，而值 3 在加载指令执行时仍然不可见。接下来，我们将分析该测试以及其他测试。

<<<
[[litmus-key]]
.本附录中绘制的试纸测试图的符号说明
[%autowidth,cols="<,<",align="center",float="center",options="header",]
|===
|边缘 |完整名称（以及解释）
|rf |读取来源（从每个存储到返回该存储写入值的加载）

|co |一致性（每个地址的存储之间的全序关系）

|fr |从读取（从每个加载到存储，返回该存储值的共后继）

|ppo |保留程序顺序

|fence |由 FENCE 指令强制执行的顺序

|addr |地址依赖性

|ctrl |控制依赖性

|data |数据依赖性
|===

图表位于每个试纸测试的右侧，展示了特定执行候选的可视化表示。这些图表采用在内存模型文献中常见的符号表示法，用于约束可能导致该执行的全局内存顺序集合。该符号表示法也是本手册中 herd 模型的基础，具体符号解释可参见 <<litmus-key>>。在列出的关系中，rf 边缘、co 边缘、fr 边缘和 ppo 边缘直接约束全局内存顺序（fence、addr、data 以及某些 ctrl 边缘也通过 ppo 约束）。其他边缘（如硬件线程内的 rf 边缘）提供信息，但不直接约束全局内存顺序。

例如，在 <<litmus-sample>> 中，`a0=1` 只有在以下任一条件为真时才会发生：

* (b) 出现在 (a) 之前的全局内存顺序中（并且在一致性顺序中 co）。但这违反了 RVWMO 的 PPO 规则 `ppo:->st`。从 (b) 到 (a) 的 co 边缘突出了这一矛盾。
* (a) 出现在 (b) 之前的全局内存顺序中（并且在一致性顺序中 co）。然而，这违反了加载值公理，因为 (a) 不是在程序顺序中 (c) 之前的最新匹配存储。从 (c) 到 (b) 的 fr 边缘突出了这一矛盾。

由于这两种情况都不满足 RVWMO 公理，`a0=1` 结果被禁止的。

除了本附录中描述的内容外，还有一个包含超过七千个试纸测试的测试套件，位于 https://github.com/litmus-tests/litmus-tests-riscv。
[NOTE]
====
试纸测试库还提供了如何在 RISC-V 硬件上运行试纸测试以及如何将结果与操作模型和公理模型进行比较的说明。

未来，我们预计将这些内存模型试纸测试适配为 RISC-V 合规性测试套件的一部分。
====
=== 解释 RVWMO 规则

本节提供了对所有 RVWMO 规则和公理的解释和示例。

==== 保留程序顺序和全局内存顺序

保留程序顺序表示在全局内存顺序中必须遵循的程序顺序子集。具体来说，如果同一硬件线程中的事件按保留程序顺序排序，它们必须在其他硬件线程和/或观察者的角度按照这一顺序出现；而如果事件不受保留程序顺序限制，它们可以在其他硬件线程和/或观察者的角度进行重新排序。

非正式地讲，全局内存顺序表示加载和存储执行的顺序。尽管当前的内存模型文献已不再以执行为基础来构建规范，但这一概念对帮助直观理解内存模型仍然至关重要。加载执行指的是加载指令的返回值已确定，而存储执行则不仅指指令已经在流水线中执行，更意味着它的值已传播到全局可见的内存中。从这一角度来看，全局内存顺序代表了内存系统和一致性协议的作用，它们将每个硬件线程发出的（可能已重新排序的）内存访问交织成一个全体硬件线程一致同意的全局顺序。

加载执行的顺序并不总是直接反映两个加载返回值的相对时间顺序。特别地，加载 _b_ 可能在加载 _a_ 之前执行（即 _b_ 可能先于 _a_ 执行，并且在全局内存顺序中 _b_ 可能排在 _a_ 之前），但 _a_ 仍然可能返回比 _b_ 更旧的值。这种不一致现象反映了（其中之一）缓冲区对核心和内存交互的影响。例如，_b_ 可能从存储缓冲区返回一个值，而 _a_ 则忽略了这个更新的存储，反而从内存读取到更旧的值。为了考虑这种情况，每次加载执行时，返回的值是由加载值公理所决定的，而不仅仅是严格依赖于全局内存顺序中最接近的存储。

[[loadvalueaxiom, 加载值公理]]
==== 加载值公理

[IMPORTANT]
====
<<ax-load>>: 每个加载 _i_ 返回的每个字节的值是由以下商定的、在全局内存顺序中最新的写入该字节的存储决定的：

. 写入该字节且在全局内存顺序中先于 _i_ 的存储
. 写入该字节且在程序顺序中先于 _i_ 的存储
====

保留程序顺序不必严格遵守一个存储后跟加载的顺序，只要它们访问的是重叠地址。这种复杂性源于几乎所有实现中普遍存在存储缓冲区。非正式地说，加载可能通过从存储缓冲区转发返回值，虽然该存储仍停留在缓冲区中，并未写回全局内存。因此，其他硬件线程可能会观察到加载在存储之前执行。

考虑 <<litms_sb_forward>>。在含有存储缓冲区的实现上运行该程序时，可能会得到最终结果 a0=1，_a1=0_，a2=1，a3=0，其执行过程如下：

[[litms_sb_forward]]
.存储缓冲区转发试纸测试（允许的结果）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",align="center"]
!===
2+^!Hart 0 2+^!Hart 1
2+^!li t1, 1 2+^!li t1, 1
2+<!(a) sw t1,0(s0) 2+!(e) sw t1,0(s1)
2+<!(b) lw a0,0(s0) 2+!(f) lw a2,0(s1)
2+<!(c) fence r,r 2+!(g) fence r,r
2+<!(d) lw a1,0(s1) 2+!(h) lw a3,0(s0)
4+^!Outcome: `a0=1`, `a1=0`, `a2=1`, `a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_sb_fwd.txt[]
a! image::graphviz/litmus_sb_fwd.png[]
!===
|===

* (a) 执行并进入第一个硬件线程的私有存储缓冲区
* (b) 执行并从 (a) 中通过存储缓冲区转发其返回值 1
* (c) 执行，因为之前的所有加载（即 (b)）都已完成
* (d) 执行并从内存中读取值 0
* (e) 执行并进入第二个硬件线程的私有存储缓冲区
* (f) 执行并从 (e) 中通过存储缓冲区转发其返回值 1
* (g) 执行，因为之前的所有加载（即 (f)）都已完成
* (h) 执行并从内存中读取值 0
* (a) 从第一个硬件线程的存储缓冲区排出到内存
* (e) 从第二个硬件线程的存储缓冲区排出到内存

因此，内存模型必须能够解释这种行为。

换句话说，假设保留程序顺序的定义包括以下假设规则：如果内存访问 _a_ 在程序顺序中先于内存访问 _b_，并且 _a_ 和 _b_ 访问相同的内存位置，_a_ 是写操作，_b_ 是读操作，那么 _a_ 在保留程序顺序中先于 _b_（因此也在全局内存顺序中先于 _b_）。称之为“规则 X”。那么我们得到以下结果：

* (a) 先于 (b)：根据规则 X
* (b) 先于 (d)：根据规则 <<overlapping-ordering, 4>>
* (d) 先于 (e)：根据加载值公理。否则，如果 (e) 先于 (d)，那么 (d) 将被要求返回 1。（这是一个完全合法的执行；只是这不是我们讨论的执行）
* (e) 先于 (f)：根据规则 X
* (f) 先于 (h)：根据规则 <<overlapping-ordering, 4>>
* (h) 先于 (a)：根据加载值公理，如上所述。

全局内存顺序必须是一个全序，而不是循环的，因为循环意味着每个事件都发生在自身之前，这是不可能的。因此，提议的执行将被禁止，添加规则 X 会禁用具有存储缓冲区转发的实现，显然这是不可接受的。

尽管如此，即使在全局内存顺序中 (b) 先于 (a) 和/或 (f) 先于 (e)，在这个例子中唯一合理的情况是 (b) 返回 (a) 写入的值，同样 (f) 返回 (e) 写入的值。这种组合符合加载值公理定义中的第二种选择。即便 (b) 在全局内存顺序中先于 (a)，由于 (a) 在 (b) 执行时仍在存储缓冲区中，(a) 对 (b) 仍然可见。因此，尽管 (b) 先于 (a)，(b) 应该返回 (a) 写入的值，因为在程序顺序中 (a) 先于 (b)。类似地，这也适用于 (e) 和 (f)。

[[litmus_ppoca]]
.用于测试存储缓冲区行为的关键
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
.用于测试存储缓冲区转发行为的 PPOCA 试纸测试（允许的结果）
|===
|
[%autowidth,cols="^,<,^,<",options="header",float="center",align="center"]
!===
2+^!Hart 0 2+^!Hart 1
! !li t1, 1 !!li t1, 1
!(a) !sw t1,0(s0) !!LOOP:
!(b) !fence w,w !(d) !lw a0,0(s1)
!(c) !sw t1,0(s1) !!beqz a0, LOOP
2+! !(e) !sw t1,0(s2)
2+! !(f) !lw a1,0(s2)
2+! ! !xor a2,a1,a1
2+! ! !add s0,s0,a2
2+! !(g) !lw a2,0(s0)
4+!Outcome: `a0=1`, `a1=1`, `a2=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_ppoca.txt[]
a! image::graphviz/litmus_ppoca.png[]
!===
|===

另一个用于测试存储缓冲区行为的测试如 <<litmus_ppoca>> 所示。在这个例子中，由于控制依赖性，(d) 在 (e) 之前排序，由于地址依赖性，(f) 在 (g) 之前排序。然而，(e) 不一定在 (f) 之前排序，即使 (f) 返回 (e) 写入的值。这可能对应于以下事件顺序：

* (e) 推测性执行并进入第二个硬件线程的私有存储缓冲区（但不排出到内存）
* (f) 推测性执行并从存储缓冲区中的 (e) 转发其返回值 1
* (g) 推测性执行并从内存中读取值 0
* (a) 执行，进入第一个硬件线程的私有存储缓冲区，并排出到内存
* (b) 执行并退休
* (c) 执行，进入第一个硬件线程的私有存储缓冲区，并排出到内存
* (d) 执行并从内存中读取值 1
* (e)、(f) 和 (g) 提交，因为推测结果是正确的
* (e) 从存储缓冲区排出到内存

[[atomicityaxiom]]
==== 原子性公理

[IMPORTANT]
====
<<ax-atom, 原子性公理>>（对齐原子操作）：如果 r 和 w 是硬件线程 h 中通过对齐的 LR 和 SC 指令生成的成对加载和存储操作，且 s 是对字节 x 的存储，且 r 返回 s 写入的值，那么 s 必须在全局内存顺序中位于 w 之前，并且 s 和 w 之间在全局内存顺序中不能存在来自 h 以外硬件线程对字节 x 的存储。
====

RISC-V 架构将原子性概念与排序概念分离。与 TSO 等架构不同，RISC-V 原子操作在 RVWMO 下默认不强制任何排序要求。排序语义仅由适用的 PPO 规则保证。

RISC-V 包含两种类型的原子操作：AMO 和 LR/SC 对。这两者在概念上表现不同。LR/SC 表现为旧值被带到核心，修改，然后写回内存，同时对该内存位置保持保留。AMO 则表现为直接在内存中执行。因此，AMO 本质上是原子的，而 LR/SC 对在原子性方面略有不同，即在原硬件线程保持保留期间，内存位置不会被其他硬件线程修改。

[frame=none]
|====
|(a) lr.d a0, 0(s0) |(a) lr.d a0, 0(s0) |(a) lr.w a0, 0(s0) |(a) lr.w a0, 0(s0)

|(b) sd t1, 0(s0)  |(b) sw t1, 4(s0)  |(b) sw t1, 4(s0) |(b) sw t1, 4(s0)

|(c) sc.d t3, t2, 0(s0) |(c) sc.d t3, t2, 0(s0) |(c) sc.w t3, t2, 0(s0) |(c) addi s0, s0, 8 

|(d) sc.w t3, t2, 8(s0)|||
|====
[[litmus_lrsdsc]]
<<litmus_lrsdsc, 图 4>>：在所有四个（独立）实例中，最终的条件存储指令允许但不保证成功。

原子性公理禁止其他硬件线程的存储在全局内存顺序中插入到 LR 和与该 LR 配对的 SC 之间。然而，它不禁止加载在程序顺序或全局内存顺序中插入到配对操作之间，也不禁止来自同一硬件线程的存储，或者对非重叠内存位置的存储在程序顺序或全局内存顺序中插入到配对操作之间。例如，在 <<litmus_lrsdsc>> 中，SC 指令可能（但并不保证）成功。成功的原因是插入的非条件存储来自与配对加载和条件存储指令相同的硬件线程。因此，内存系统不会导致条件存储指令失败，即便它与保留的内存位置共享同一缓存行的其他部分。

原子性公理技术上允许 LR 和 SC 触及不同地址或使用不同的访问大小，虽然这种情况在实践中不常见。LR/SC 对之间存储重叠于 LR 或 SC 引用的内存位置的情况，也远少于存储仅落在同一缓存行上的情况。

[[mm-progress]]
==== 进展公理

[IMPORTANT]
====
<<ax-prog, 进展公理>>：在全局内存顺序中，任何内存操作之前都不能有无限序列的其他内存操作。
====

进展公理确保了最小的持续进展。它确保一个硬件线程的存储将在有限时间内最终对系统中的其他硬件线程可见，并且其他硬件线程的加载最终能够读取这些值（或其后继）。没有这个规则，例如，一个自旋锁可能会无限期地在一个值上旋转，即使有另一个硬件线程的存储等待解锁自旋锁。

进展公理旨在不对 RISC-V 实现中的硬件线程施加任何其他公平性、延迟或服务质量的概念。任何更强的公平性概念由 ISA 的其余部分和/或平台和/或设备定义和实现。

在几乎所有情况下，标准缓存一致性协议将自然满足持续进展公理。具有非一致性缓存的实现可能需要提供其他机制，以确保所有存储（或其后继）最终对所有硬件线程可见。

[[mm-overlap]]
==== 重叠地址排序（<<overlapping-ordering, 规则 1-3>>）

[NOTE]
====
<<overlapping-ordering, 规则 1>>：b 是存储，a 和 b 访问重叠的内存地址

<<overlapping-ordering, 规则 2>>：a 和 b 是加载，x 是 a 和 b 都读取的字节，在程序顺序中 a 和 b 之间没有对 x 的存储，并且 a 和 b 返回由不同内存操作写入的 x 的值

<<overlapping-ordering, 规则 3>>：a 是由 AMO 或 SC 指令生成的，b 是加载，并且 b 返回由 a 写入的值
====

后者是存储的同地址排序是直接的：加载或存储永远不能与后来的存储到重叠的内存位置重新排序。从微架构的角度来看，一般来说，如果推测是无效的，撤销推测性重新排序的存储是极为困难，因此模型不允许这种行为。另一方面，从存储到后来的加载的同地址排序不需要强制执行。如<<loadvalueaxiom>>中所述，这反映了实现从缓冲存储转发值到后续加载的可观察行为。

同地址加载-加载排序要求要微妙得多。基本要求是，较年轻的加载不得返回比同一硬件线程中较旧的加载返回的值更旧的值。这通常被称为“CoRR”（加载-加载对的一致性），或作为更广泛的“同一位置的顺序一致性”要求的一部分。过去一些架构放宽了同地址加载-加载排序，但事后看来，这通常被认为使编程模型过于复杂，因此 RVWMO 要求强制执行 CoRR 排序。然而，由于全局内存顺序对应于加载执行的顺序，而不是返回值的顺序，因此需要一些间接方法来捕捉 CoRR 要求。

[[frirfi]]
.试纸测试 MP+fence.w.w+fri-rfi-addr（允许结果）

[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
.试纸测试 MP+fence.w.w+fre-rfi-addr（允许结果）
|===
|
[%autowidth,cols="^,<,^,<",options="header",float="center",align="center"]
!===
2+!硬件线程 0 2+^!硬件线程 1
!!li t1, 1 !!li t2, 2
>!(a) !sw t1,0(s0) >!(d) !lw a0,0(s1)
>!(b) !fence w, w >!(e) !sw t2,0(s1)
>!(c) !sw t1,0(s1) >!(f) !lw a1,0(s1)
! ! >!(g) !xor t3,a1,a1
! ! >!(h) !add s0,s0,t3
! ! >!(i) !lw a2,0(s0)
4+^!结果：`a0=1`，`a1=2`，`a2=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_mp_fenceww_fri_rfi_addr.txt[]
a! image::graphviz/litmus_mp_fenceww_fri_rfi_addr.png[]
!===
|===
考虑 <<frirfi>> 的试纸测试，这是更一般的“fri-rfi”模式的一个特定实例。“fri-rfi”一词指的是 (d)、(e)、(f) 的序列：(d)“从读取”（即从早期写入读取）(e) 是同一硬件线程，并且 (f) 从 (e) 读取，它们在同一硬件线程中。

从微架构的角度来看，结果 `a0=1`，`a1=2`，`a2=0` 是合法的（以及其他各种不太微妙的结果）。直观地说，以下将产生所讨论的结果：

* (d) 停顿（无论出于何种原因；可能是等待某些其他前面的指令）
* (e) 执行并进入存储缓冲区（但尚未排出到内存）
* (f) 执行并从存储缓冲区中的 (e) 转发
* (g)、(h) 和 (i) 执行
* (a) 执行并排出到内存，(b) 执行，(c) 执行并排出到内存
* (d) 解除停顿并执行
* (e) 从存储缓冲区排出到内存

这对应于 (f)、(i)、(a)、(c)、(d)、(e) 的全局内存顺序。注意，即使 (f) 在 (d) 之前执行，(f) 返回的值也比 (d) 返回的值更新。因此，这种执行是合法的，不违反 CoRR 要求。

同样，如果两个背靠背的加载返回由同一存储写入的值，则它们也可以在全局内存顺序中无序出现，而不会违反 CoRR。注意，这与说两个加载返回相同的值不同，因为两个不同的存储可能写入相同的值。

[[litmus-rsw]]
.试纸测试 RSW（允许结果）

[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<",options="header",float="center",align="center"]
!===
2+!Hart 0 2+^!Hart 1
2+!li t1, 1 >!(d) <!lw  a0,0(s1)
>!(a) <!sw t1,0(s0) >!(e) !xor t2,a0,a0
>!(b) <!fence w, w >!(f) !add s4,s2,t2
>!(c) <!sw t1,0(s1) >!(g) !lw  a1,0(s4)
! ! >!(h) !lw  a2,0(s2)
! ! >!(i) !xor t3,a2,a2
! ! >!(j) !add s0,s0,t3
! ! >!(k) !lw  a3,0(s0)
4+!Outcome: `a0=1`, `a1=v`, `a2=v`, `a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_rsw.txt[]
a! image::graphviz/litmus_rsw.png[]
!===
|===

考虑 <<litmus-rsw>> 的试纸测试。
结果 `a0=1`，`a1=v`，`a2=v`，`a3=0`（其中 _v_ 是由另一个硬件线程写入的某个值）可以通过允许 (g) 和 (h) 重新排序来观察到。这可能是推测性完成的，并且微架构可以通过嗅探缓存失效并发现没有失效来证明这种推测是合理的，因为在 (g) 之后重放 (h) 将返回相同存储写入的值。因此，假设 `a1` 和 `a2` 最终会得到相同存储写入的值，(g) 和 (h) 可以合法地重新排序。与此执行对应的全局内存顺序将是 (h)、(k)、(a)、(c)、(d)、(g)。

在 <<litmus-rsw>> 的测试中，`a1` 不等于 `a2` 的执行确实要求 (g) 在全局内存顺序中出现在 (h) 之前。允许 (h) 在全局内存顺序中出现在 (g) 之前在这种情况下会导致违反 CoRR，因为这样 (h) 将返回比 (g) 返回的值更旧的值。因此，<<overlapping-ordering, rule 2>> 禁止这种 CoRR 违规的发生。因此，<<overlapping-ordering, rule 2>> 在所有情况下强制执行 CoRR 的同时，足够弱以允许在实际微架构中常见的 "RSW" 和 "fri-rfi" 模式。

还有一个重叠地址规则：<<overlapping-ordering, rule 3>> 仅仅指出，在 AMO 或 SC 成功执行之前，不能将值从 AMO 或 SC 返回到后续加载。这在概念上自然地遵循 AMO 和 SC 指令旨在在内存中原子执行的观点。然而，值得注意的是，<<overlapping-ordering, rule 3>> 规定硬件甚至不能非推测性地将 AMOSWAP 存储的值转发到后续加载，即使对于 AMOSWAP，该存储值实际上并不依赖于内存中的先前值，其他 AMO 也是如此。同样，即使在 SC 存储值不依赖于配对 LR 返回的值时，从 SC 存储值转发到后续加载也是如此。

上述三个 PPO 规则也适用于仅部分重叠的内存访问。例如，当使用不同大小的访问来访问同一对象时可能会发生这种情况。还要注意，对于两个重叠的内存操作，基地址不一定相同。当使用未对齐的内存访问时，重叠地址 PPO 规则适用于每个组件内存访问。

[[mm-fence]]
==== Fences (<<overlapping-ordering, Rule 4>>)

[IMPORTANT]
====
规则 <<overlapping-ordering, 4>>：存在一个 FENCE 指令将 a 排在 b 之前
====

默认情况下，FENCE 指令确保程序顺序中栅栏之前的所有内存访问（“前驱集”）在全局内存顺序中出现在程序顺序中栅栏之后的内存访问（“后继集”）之前。然而，栅栏可以选择进一步限制前驱集和/或后继集到更小的内存访问集，以提供一些加速。具体来说，栅栏具有 PR、PW、SR 和 SW 位，这些位限制前驱集和/或后继集。前驱集仅在 PR（分别为 PW）设置时包括加载（分别为存储）。同样，后继集仅在 SR（分别为 SW）设置时包括加载（分别为存储）。

FENCE 编码目前有九种非平凡组合的四个位 PR、PW、SR 和 SW，加上一个额外的编码 FENCE.TSO，便于映射“获取+释放”或 RVTSO 语义。其余七种组合具有空的前驱集和/或后继集，因此是无操作的。在十种非平凡选项中，只有六种在实践中常用：

* FENCE RW,RW
* FENCE.TSO
* FENCE RW,W
* FENCE R,RW
* FENCE R,R
* FENCE W,W

除了 PR、PW、SR 和 SW 组合外，其他 FENCE 指令组合均为保留。我们建议程序员使用这六种组合，因为其他组合可能与内存模型产生意外或未预见的交互。

最后，由于 RISC-V 采用了多副本原子内存模型，程序员可以在每个线程的上下文中推理栅栏位。与非多副本原子内存模型中存在的“栅栏累积性”概念不同，这种模型不需要考虑这种复杂性。

[[sec:memory:acqrel]]
==== 显式同步（<<overlapping-ordering, Rules 5-8>>）

[IMPORTANT]
====
<<overlapping-ordering, Rule 5>>：a 具有获取注释

<<overlapping-ordering, Rule 6>>：b 具有释放注释

<<overlapping-ordering, Rule 7>>：a 和 b 都具有 RCsc 注释

<<overlapping-ordering, Rule 8>>：a 与 b 配对
====

获取操作（如在关键部分开始时的操作）要求程序顺序中的所有后续内存操作在全局内存顺序中依次跟随获取操作。这保证了关键部分中的所有加载和存储都能与保护它的同步变量保持一致并保持最新。获取排序可以通过以下两种方式之一来强制：使用获取注释仅对同步变量强制排序，或者使用 FENCE R,RW 强制对所有之前的加载进行排序。

[[spinlock_atomics]]
.带有原子操作的自旋锁
[source%linenums,asm]
....
          sd           x1, (a1)     # 任意无关存储
          ld           x2, (a2)     # 任意无关加载
          li           t0, 1        # 初始化交换值。
      again:
          amoswap.w.aq t0, t0, (a0) # 尝试获取锁。
          bnez         t0, again    # 如果被持有则重试。
          # ...
          # 关键部分。
          # ...
          amoswap.w.rl x0, x0, (a0) # 通过存储 0 释放锁。
          sd           x3, (a3)     # 任意无关存储
          ld           x4, (a4)     # 任意无关加载
....

考虑 <<spinlock_atomics, 示例 1>>。
因为这个例子使用了 _aq_，所以关键部分中的加载和存储在全局内存顺序中保证出现在用于获取锁的 AMOSWAP 之后。然而，假设 `a0`、`a1` 和 `a2` 指向不同的内存位置，关键部分中的加载和存储在全局内存顺序中可能会或可能不会出现在示例开头的“任意无关加载”之后。

[[spinlock_fences]]
.带有栅栏的自旋锁
[source%linenums,asm]
....
          sd           x1, (a1)     # 任意无关存储
          ld           x2, (a2)     # 任意无关加载
          li           t0, 1        # 初始化交换值。
      again:
          amoswap.w    t0, t0, (a0) # 尝试获取锁。
          fence        r, rw        # 强制“获取”内存排序
          bnez         t0, again    # 如果被持有则重试。
          # ...
          # 关键部分。
          # ...
          fence        rw, w        # 强制“释放”内存排序
          amoswap.w    x0, x0, (a0) # 通过存储 0 释放锁。
          sd           x3, (a3)     # 任意无关存储
          ld           x4, (a4)     # 任意无关加载
....

考虑 <<spinlock_fences, 示例 2>> 中的替代方案。在这种情况下，即使 AMOSWAP 操作没有使用 _aq_ 位强制排序，栅栏依然会确保 AMOSWAP 在全局内存顺序中出现在关键部分的所有加载和存储之前。然而，这个栅栏还会强制执行其他的排序要求：它还要求程序开头的“任意无关加载”在全局内存顺序中出现在关键部分的加载和存储之前（但是，这个栅栏并不要求“任意无关存储”在全局内存顺序中出现在关键部分的存储之前）。因此，栅栏强制的排序比 _aq_ 强制的排序要宽松一些。

释放排序与获取排序完全相同，只是方向相反。释放语义要求程序顺序中所有释放操作之前的加载和存储也在全局内存顺序中出现在释放操作之前，这确保了，关键部分中的内存访问会出现在释放锁存储之前。释放语义可以通过释放注释或 FENCE RW,W 来强制执行。类似地，在同一个示例中，关键部分的加载和存储与代码段末尾的“任意无关存储”之间的排序仅由 <<spinlock_fences, 示例 2>> 中的 FENCE RW,W 强制执行，而不是由 <<spinlock_atomics, 示例 1>> 中的 rl 强制执行。

使用 RCpc 注释时，存储释放到加载获取的排序不会被强制执行，这对于移植在 TSO 和/或 RCpc 内存模型下编写的代码非常有帮助。如果需要强制存储释放到加载获取的排序，代码必须使用存储释放-RCsc 和加载获取-RCsc 操作，从而使 PPO 规则 7 适用。RCpc 对 C/C++ 中的许多应用程序来说已经足够，但对于 C/C++、Java 和 Linux 中的其他很多用例来说则不足够，更多细节请参见 <<memory_porting, 内存移植>>。

PPO 规则 8 表明 SC 必须在全局内存顺序中出现在其配对的 LR 之后，这一点自然来自于 LR/SC 用法的常见模式，即执行原子读-修改-写操作，因为它们之间存在数据依赖性。然而，即便存储的值在语法上不依赖于配对的 LR 返回值，PPO 规则 8 依然适用。

最后，我们强调，像栅栏一样，程序员在分析排序注释时无需担心“累积性”。

[[sec:memory:dependencies]]
==== 句法依赖（<<overlapping-ordering, 规则 9-11>>）

[[ppo-addr]]
[IMPORTANT]
====
<<overlapping-ordering, 规则 9>>：b 对 a 有句法地址依赖

<<overlapping-ordering, 规则 10>>：b 对 a 有句法数据依赖

<<overlapping-ordering, 规则 11>>：b 是存储操作，且 b 对 a 有句法控制依赖
====

RVWMO 内存模型遵循加载到同一硬件线程后续内存操作之间的依赖关系。Alpha 内存模型以不强制执行这些依赖关系的顺序为特征，但现代硬件和软件内存模型认为允许重排序依赖指令是混乱且不直观的。此外，现代代码有时故意依赖于这种依赖关系，作为一种简便的排序强制手段。

在 <<mem-dependencies>> 中，术语定义如下：指令会将依赖关系从其源寄存器传递到目标寄存器，前提是目标寄存器的写入值是源寄存器值的函数。对于大部分指令，目标寄存器携带来自所有源寄存器的依赖关系。然而，对于内存指令，目标寄存器的写入值来自内存系统，而不是直接从源寄存器中获取，因此打破了依赖关系链。对于无条件跳转指令，目标寄存器的值来自当前的 _pc_，因此内存模型不会认为 _pc_ 是源寄存器，因此 JALR 指令（唯一带有源寄存器的跳转）不会携带从 _rs1_ 到 _rd_ 的依赖关系。

[[fflags]]
.(c) 通过 fflags 对 (a) 和 (b) 都有句法依赖，fflags 是 (a) 和 (b) 都隐式累积到的目标寄存器
[.text-center,source%linenums,asm]
----
(a) fadd f3,f1,f2
(b) fadd f6,f4,f5
(c) csrrs a0,fflags,x0
----

累积到目标寄存器，而不是直接写入它的行为，反映了像 `fflags` 之类 CSR 的特性。尤其是，累积到寄存器并不会覆盖先前的写入或累积。例如，在 <<fflags>> 中，(c) 对 (a) 和 (b) 都存在句法依赖。

与其他现代内存模型一致，RVWMO 内存模型使用句法依赖而非语义依赖。换句话说，依赖关系的定义取决于不同指令访问的寄存器的身份，而非这些寄存器的实际内容。这意味着即便计算本身似乎可以被“优化掉”，也必须强制执行地址、控制或数据依赖。这样的设计确保了 RVWMO 依然能够与那些将虚假句法依赖作为轻量级排序机制的代码保持兼容。

[[address]]
.句法地址依赖
[.text-center, source%linenums, asm]
----
ld a1,0(s0)
xor a2,a1,a1
add s1,s1,a2
ld a5,0(s1)
----

例如，从第一条指令生成的内存操作到最后一条指令生成的内存操作存在句法地址依赖，尽管 `a1` XOR `a1` 为零，因此对第二次加载访问的地址没有影响。

依赖关系作为轻量级同步机制的优势在于，排序强制仅作用于特定的两条指令，其他不相关的指令可以由实现自由地重新排序。一个替代方案是使用加载获取，但这会强制第一条加载与所有后续指令排序。另一种替代方案是使用 FENCE R,R，它将包括所有之前和之后的加载，从而使得该选项的开销更大。

[[control1]]
.句法控制依赖
[.text-center, source%linenums, asm]
----
lw x1,0(x2)
bne x1,x0,next
sw x3,0(x4)
next: sw x5,0(x6)
----

控制依赖与地址和数据依赖的行为不同，因为控制依赖总是扩展到程序顺序中初始目标之后的所有指令。考虑 <<control1>>，`next` 处的指令将始终执行，但最后一条指令生成的内存操作仍然对第一条指令生成的内存操作有控制依赖。

[[control2]]
.另一个句法控制依赖
[.text-center,source%linenums,asm]
----
lw x1,0(x2)
bne x1,x0,next
next: sw x3,0(x4)
----

同样，考虑 <<control2>>。即使两个分支结果具有相同的目标，从这个片段中的第一条指令生成的内存操作到最后一条指令生成的内存操作仍然存在控制依赖。这一定义的控制依赖比在其他上下文（例如 C++）中看到的稍强，但它符合文献中控制依赖的标准定义。

值得指出的是，PPO 规则 <<overlapping-ordering, 9-11>> 被有意设计为遵循从成功的条件存储指令开始的依赖关系。通常，SC 指令后面会有一个条件分支，用于检查 SC 是否成功；这意味着 SC 生成的存储操作与分支后的任何内存操作之间存在控制依赖关系。PPO 规则 <<ppo, 11>> 规定，任何后续的存储操作会在全局内存顺序中出现在 SC 生成的存储操作之后。然而，由于控制、地址和数据依赖是根据内存操作定义的，且不成功的 SC 不会生成内存操作，因此不强制执行不成功的 SC 与其依赖指令之间的顺序。最后，由于 SC 仅在成功时从源寄存器将依赖关系传递到 rd，因此不成功的 SC 不会影响全局内存顺序。

[[litmus_lb_lrsc]]
.LB 试纸测试的一个变体（结果禁止）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<",float="center",align="center"]
!===
4+!初始值：0(s0)=1；0(s1)=1
4+!
2+^!Hart 0 2+^!Hart 1 
!(a) !ld a0,0(s0) !(e) !ld a3,0(s2)
!(b) !lr a1,0(s1) !(f) !sd a3,0(s0)
!(c) !sc a2,a0,0(s1) ! !
!(d) !sd a2,0(s2) ! !
4+!结果：`a0=0`，`a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_lb_lrsc.txt[]
a! image::graphviz/litmus_lb_lrsc.png[]
!===
|===

此外，选择尊重从条件存储指令开始的依赖关系，能够有效避免某些类似凭空出现的行为。考虑 <<litmus_lb_lrsc>>。假设某个实现偶尔能够提前保证条件存储操作会成功。在这种情况下，(c) 可以提前返回 0 给 `a2`（在实际执行之前），允许序列 (d)、(e)、(f)、(a) 和 (b) 执行，然后 (c) 可能仅在那时执行（成功）。这将意味着 (c) 将其成功值写入 `0(s1)`！幸运的是，通过 RVWMO 内存模型尊重从成功的 SC 指令生成的存储开始的依赖关系，避免了这种情况及类似问题的出现。

我们还要指出，指令之间的句法依赖只有在它们表现为句法地址、控制或数据依赖时才有效。例如：在 <<source-dest-regs>> 中，两个 `F` 指令之间的句法依赖并不意味着这两个指令必须按顺序执行。这类依赖关系仅会在稍后访问 CSR 标志时，导致从两个 `F` 指令到相应的 CSR 指令之间产生依赖。

[[memory-ppopipeline]]
==== 流水线依赖（<<overlapping-ordering, 规则 12-13>>）

[[addrdatarfi]]
[IMPORTANT]
====
<<overlapping-ordering, 规则 12>>：b 是一个加载指令，并且在程序顺序中 a 和 b 之间存在某个存储 m，m 对 a 有地址或数据依赖，并且 b 返回 m 写入的值

<<overlapping-ordering, 规则 13>>：b 是一个存储指令，并且在程序顺序中 a 和 b 之间存在某个指令 m，m 对 a 有地址依赖
====

[[litmus_datarfi]]
.由于 PPO <<overlapping-ordering, 规则 12>> 和 (d) 到 (e) 的数据依赖，(d) 也必须在全局内存顺序中先于 (f)（结果禁止）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
!===
2+!硬件线程 0 2+! 硬件线程 1
! !li t1, 1 !(d) !lw a0, 0(s1)
!(a) !sw t1,0(s0) !(e) !sw a0, 0(s2)
!(b) !fence w, w !(f) !lw a1, 0(s2)
!(c) !sw t1,0(s1) ! !xor a2,a1,a1
! ! ! !add s0,s0,a2
! ! !(g) !lw a3,0(s0)
4+!结果：`a0=1`，`a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_datarfi.txt[]
a! image::graphviz/litmus_datarfi.png[]
!===
|===

PPO 规则 <<overlapping-ordering, 12>> 和 <<overlapping-ordering, 13>> 反映了几乎所有实际处理器流水线实现的行为。规则 <<overlapping-ordering, 12>> 规定加载不能从存储转发，直到该存储的地址和数据已知。考虑 <<litmus_datarfi>> (f) 不能执行，直到 (e) 的数据已解析，因为 (f) 必须返回 (e) 写入的值（或全局内存顺序中更晚的值），并且在 (d) 执行之前，(e) 的写回不能覆盖旧值。因此，(f) 永远不会在 (d) 执行之前执行。

.由于 (e) 和 (g) 之间的额外存储，(d) 不再需要先于 (g)（结果允许）

[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<",float="center",align="center",options="header",]
!===
2+!Hart 0 2+!Hart 1
2+!li t1, 1 2+^!li t1, 1
!(a) !sw t1,0(s0) !(d) !lw a0, 0(s1)
!(b) !fence w, w !(e) !sw a0, 0(s2)
!(c) !sw t1,0(s1) !(f) !sw t1, 0(s2)
! ! !(g) !lw a1, 0(s2)
! ! ! !xor a2,a1,a1
! ! ! !add s0,s0,a2
! ! !(h) !lw a3,0(s0)
4+!Outcome: `a0=1`, `a3=0`
!===
|
!===
//a! graphviz::images/graphviz/litmus_datacoirfi.txt[]
a! image::graphviz/litmus_datacoirfi.png[]
!===
|===

如果在 (e) 和 (f) 之间有另一个对相同地址的存储，如 <<litmus:addrdatarfi_no>> 中所示，那么 (f) 将不再依赖于 (e) 的数据解析，因此 (f) 对 (d) 的依赖将被打破，(d) 生成 (e) 的数据。

规则 <<overlapping-ordering, 13>> 对前一规则做了类似的观察：存储不能在内存中执行，直到所有可能访问相同地址的先前加载都已执行。这样的加载必须在存储之前执行，但如果存储在加载有机会读取旧值之前覆盖了内存中的值，则加载不能这样做。同样，存储通常不能执行，直到知道前面的指令不会因地址解析失败而导致异常，从这个意义上说，规则 13 可以看作是规则 <<overlapping-ordering, 11>> 的一个特例。

[[litmus:addrdatarfi_no]]
.由于 (d) 到 (e) 的地址依赖，(d) 也先于 (f)（结果禁止）
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,cols="^,<,^,<"float="center",align="center",options="header"]
!===
2+!硬件线程 0 2+^!硬件线程 1
2+! 2+^!li t1, 1
!(a) !lw a0,0(s0) !(d) !lw a1, 0(s1)
!(b) !fence rw,rw !(e) !lw a2, 0(a1)
!(c) !sw s2,0(s1) !(f) !sw t1, 0(s0)
4+!结果：`a0=1`，`a1=t`
!===
|
!===
//a! graphviz::images/graphviz/litmus_addrpo.txt[]
a! image:graphviz/litmus_addrpo.png[]
!===
|===

考虑 <<litmus:addrdatarfi_no>> (f) 不能执行，直到 (e) 的地址解析，因为地址可能匹配；即 `a1=s0`。因此，在 (d) 执行并确认地址确实重叠之前，(f) 不能发送到内存。

=== 超越主内存

RVWMO 目前不尝试正式描述 FENCE.I、SFENCE.VMA、I/O 栅栏和 PMA 的行为。所有这些行为将在未来的形式化中描述。与此同时，FENCE.I 的行为在 <<zifencei>> 中描述，SFENCE.VMA 的行为在 RISC-V 指令集特权架构手册中描述，I/O 栅栏和 PMA 的行为如下所述。

==== 一致性和可缓存性

RISC-V 特权 ISA 定义了物理内存属性（PMA），其中指定了地址空间的某些部分是否一致和/或可缓存。有关完整详细信息，请参阅 RISC-V 特权 ISA 规范。这里，我们仅讨论每个 PMA 中的各种详细信息如何与内存模型相关：

* 主内存与 I/O 以及 I/O 内存排序 PMA：定义的内存模型适用于主内存区域。I/O 排序如下所述。
* 支持的访问类型和原子性 PMA：内存模型仅在每个区域支持的原语之上应用。
* 可缓存性 PMA：一般来说，可缓存性 PMA 不影响内存模型。非缓存区域的行为可能比缓存区域更严格，但无论如何，允许的行为集不会改变。然而，一些平台特定和/或设备特定的可缓存性设置可能会有所不同。
* 一致性 PMA：标记为非一致性的内存区域的内存一致性模型目前是平台特定和/或设备特定的：加载值公理、原子性公理和进展公理都可能被非一致性内存违反。然而，一致性内存不需要硬件缓存一致性协议。RISC-V 特权 ISA 规范建议不鼓励硬件非一致性区域的主内存，但内存模型与硬件一致性、软件一致性、由于只读内存而隐含的一致性、由于只有一个代理访问而隐含的一致性或其他方式兼容。
* 幂等性 PMA：幂等性 PMA 用于指定加载和/或存储可能具有副作用的内存区域，这反过来用于微架构确定，例如，预取是否合法。这一区别不影响内存模型。

==== I/O 排序

对于 I/O，加载值公理和原子性公理通常不适用，因为读取和写入可能具有设备特定的副作用，并且可能返回与最近存储到相同地址的值不同的值。然而，以下保留程序顺序规则通常仍适用于对 I/O 内存的访问：如果 _a_ 在程序顺序中先于 _b_，并且以下之一成立，则 _a_ 在全局内存顺序中先于 _b_：

. _a_ 在保留程序顺序中先于 _b_，如 <<memorymodel>> 中定义，获取和释放排序注释仅适用于从一个内存操作到另一个内存操作以及从一个 I/O 操作到另一个 I/O 操作，但不适用于从内存操作到 I/O 操作或反之亦然
. _a_ 和 _b_ 是对 I/O 区域重叠地址的访问
. _a_ 和 _b_ 是对相同强排序 I/O 区域的访问
. _a_ 和 _b_ 是对 I/O 区域的访问，并且与 _a_ 或 _b_ 访问的 I/O 区域相关的通道是通道 1
. _a_ 和 _b_ 是对与相同通道（除通道 0 外）相关的 I/O 区域的访问

请注意，FENCE 指令在其前驱集和后继集中区分主内存操作和 I/O 操作。要强制 I/O 操作和主内存操作之间的排序，代码必须使用带有 PI、PO、SI 和/或 SO 以及 PR、PW、SR 和/或 SW 的 FENCE。例如，要强制主内存写入和设备寄存器的 I/O 写入之间的排序，需要 FENCE W,O 或更强的排序。
[[wo]]
.排序内存和 I/O 访问
[.text-center,source%linenums,asm]
----
sd t0, 0(a0)
fence w,o 
sd a0, 0(a1)
----

当实际使用栅栏时，实现必须假设设备可能在接收到 MMIO 信号后立即尝试访问内存，并且该设备对内存的后续内存访问必须观察到所有在该 MMIO 操作之前排序的访问的效果。换句话说，在 <<wo>> 中，假设 `0(a0)` 在主内存中，`0(a1)` 是 I/O 内存中设备寄存器的地址。如果设备在接收到 MMIO 写入后访问 `0(a0)`，则根据 RVWMO 内存模型的规则，该加载必须概念上出现在第一次存储到 `0(a0)` 之后。在某些实现中，确保这一点的唯一方法是要求第一次存储在发出 MMIO 写入之前实际完成。其他实现可能会找到更积极的方法，而其他实现可能根本不需要对 I/O 和主内存访问做任何不同的事情。然而，RVWMO 内存模型不区分这些选项；它只是提供了一种与实现无关的机制来指定必须强制执行的排序。

许多架构包括“排序”和“完成”栅栏的单独概念，特别是与 I/O（与常规主内存相对）相关。排序栅栏仅确保内存操作保持顺序，而完成栅栏确保前驱访问在任何后继可见之前都已完成。RISC-V 没有明确区分排序和完成栅栏。相反，这种区别只是从 FENCE 位的不同使用中推断出来的。

对于符合 RISC-V Unix 平台规范的实现，I/O 设备和 DMA 操作需要一致地访问内存并通过强排序 I/O 通道。因此，同时由外部设备访问的常规主内存区域的访问也可以使用标准同步机制。不符合 Unix 平台规范和/或设备不一致访问内存的实现将需要使用机制（目前是平台特定或设备特定的）来强制一致性。

地址空间中的 I/O 区域应被视为这些区域的 PMA 中的非缓存区域。如果这些区域不被任何代理缓存，则可以通过 PMA 视为一致的。

本节中的排序保证可能不适用于 RISC-V 内核和设备之间的平台特定边界之外。特别是，通过外部总线（例如 PCIe）发送的 I/O 访问可能在到达最终目的地之前重新排序。在这种情况下，必须根据这些外部设备和总线的平台特定规则强制执行排序。

[[memory_porting]]
=== 代码移植和映射指南

[[tsomappings]]
.TSO 操作到 RISC-V 操作的映射
[%autowidth,float="center", align="center",cols="<,<",options="header",separator=!]
|===
!x86/TSO 操作 !RVWMO 映射
!加载 ! `l{b|h|w|d}; fence r,rw`
!存储 !`fence rw,w; s{b|h|w|d}`
!原子 RMW !`amo<op>.{w|d}.aqrl OR` +
`loop:lr.{w|d}.aq; <op>; sc.{w|d}.aqrl; bnez loop`
!栅栏 !`fence rw,rw`
|===

<<tsomappings>> 提供了 TSO 内存操作到 RISC-V 内存指令的映射。正常的 x86 加载和存储本质上都是获取-RCpc 和释放-RCpc 操作：TSO 默认强制所有加载-加载、加载-存储和存储-存储排序。因此，在 RVWMO 下，所有 TSO 加载必须映射到加载后跟 FENCE R,RW，所有 TSO 存储必须映射到 FENCE RW,W 后跟存储。TSO 原子读-修改-写和使用 LOCK 前缀的 x86 指令是完全排序的，可以通过设置 _aq_ 和 _rl_ 的 AMO 实现，或者通过设置 _aq_ 的 LR、相关的算术操作、设置 _aq_ 和 _rl_ 的 SC 以及检查成功条件的条件分支实现。在后一种情况下，LR 上的 _rl_ 注释实际上是多余的，可以省略。

<<tsomappings>> 的替代方案也是可行的。TSO 存储可以映射为设置 `rl` 的 AMOSWAP。然而，由于 RVWMO PPO 规则 <<overlapping-ordering, 3>> 禁止从 AMO 向后续加载转发值，使用 AMOSWAP 进行存储可能会导致性能下降。TSO 加载可以通过设置 aq 的 LR 进行映射：所有这类 LR 指令都是未配对的，但这一点并不排除使用 LR 进行加载。不过，再次强调，这种映射可能会对性能产生不利影响，特别是在它对保留机制的压力超出预期时。

[[powermappings]]
.Power 操作到 RISC-V 操作的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!Power 操作 !RVWMO 映射
!加载 !`l{b|h|w|d}`
!加载-保留 !`lr.{w|d}`
!存储 !`s{b|h|w|d}`
!存储-条件 !`sc.{w|d}`
!`lwsync` !`fence.tso`
!`sync` !`fence rw,rw`
!`isync` !`fence.i; fence r,r`
|===

<<powermappings>> 提供了 Power 内存操作到 RISC-V 内存指令的映射。Power ISYNC 在 RISC-V 上映射到 FENCE.I 后跟 FENCE R,R；后者的栅栏是必需的，因为 ISYNC 用于定义 RVWMO 中不存在的“控制+控制栅栏”依赖关系。

[[armmappings]]
.从ARM操作到RISC-V操作的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!ARM 操作 !RVWMO 映射
!Load !`l{b|h|w|d}`
!Load-Acquire !`fence rw, rw; l{b|h|w|d}; fence r,rw`
!Load-Exclusive !`lr.{w|d}`
!Load-Acquire-Exclusive !`lr.{w|d}.aqrl`
!Store !`s{b|h|w|d}`
!Store-Release !`fence rw,w; s{b|h|w|d}`
!Store-Exclusive !`sc.{w|d}`
!Store-Release-Exclusive !`sc.{w|d}.rl`
!`dmb` !`fence rw,rw`
!`dmb.ld` !`fence r,rw`
!`dmb.st` !`fence w,w`
!`isb` !`fence.i; fence r,r`
|===

<<armmappings>> 提供了从 ARM 内存操作到 RISC-V 内存指令的映射。由于 RISC-V 目前没有带有 _aq_ 或 _rl_ 注释的普通加载和存储操作码，ARM 的加载-获取和存储-释放操作应使用 fence 来映射。此外，为了强制存储-释放到加载-获取的顺序，在存储-释放和加载-获取之间必须有一个 FENCE RW,RW；<<armmappings>> 通过在每个获取操作前始终放置 fence 来强制执行这一点。ARM 的加载-独占和存储-独占指令同样可以映射到它们的 RISC-V LR 和 SC 等价物，但我们不在带有 _aq_ 设置的 LR 前放置 FENCE RW,RW，而是简单地也设置 _rl_。ARM 的 ISB 在 RISC-V 上映射为 FENCE.I，然后是 FENCE R,R，类似于 Power 的 ISYNC 映射。

[[linuxmappings]]
.从 Linux 内存原语到 RISC-V 原语的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!Linux 操作 !RVWMO 映射

!`smp_mb()` !`fence rw,rw`

!`smp_rmb()` !`fence r,r`

!`smp_wmb()` !`fence w,w`

!`dma_rmb()` !`fence r,r`

!`dma_wmb()` !`fence w,w`

!`mb()` !`fence iorw,iorw`

!`rmb()` !`fence ri,ri`

!`wmb()` !`fence wo,wo`

!`smp_load_acquire()` !`l{b|h|w|d}; fence r,rw`

!`smp_store_release()` !`fence.tso; s{b|h|w|d}`

!Linux 构造 !RVWMO AMO 映射

!`atomic &#60;op&#62; relaxed` !`amo &#60;op&#62;.{w|d}`

!`atomic &#60;op&#62; acquire` !`amo &#60;op&#62;.{w|d}.aq`

!`atomic &#60;op&#62; release` !`amo &#60;op&#62;.{w|d}.rl`

!`atomic &#60;op&#62;` !`amo &#60;op&#62;.{w|d}.aqrl`

!Linux 构造 !RVWMO LR/SC 映射

!`atomic &#60;op&#62; relaxed` !`loop:lr.{w|d}; &#60;op&#62;; sc.{w|d}; bnez loop`

!`atomic &#60;op&#62; acquire` !`loop:lr.{w|d}.aq; &#60;op&#62;; sc.{w|d}; bnez loop`

!`atomic &#60;op&#62; release` !`loop:lr.{w|d}; &#60;op&#62;; sc.{w|d}.aqrl^&#42;; bnez loop OR`

! !`fence.tso; loop:lr.{w|d}; &#60;op &#62;; sc.{w|d}^&#42;; bnez loop`

!`atomic &#60;op&#62;` !`loop:lr.{w|d}.aq;` `&#60;op&#62;; sc.{w|d}.aqrl; bnez loop`

|===

关于<<linuxmappings>>，其他构造（如自旋锁）应相应遵循。具有非一致性DMA的平台或设备可能需要额外的同步（如缓存刷新或失效机制）；目前，任何此类额外的同步措施是设备特定的。

<<linuxmappings>> 提供了将 Linux 内存排序宏映射到 RISC-V 内存指令的映射方案。在支持一致性 DMA 的平台上，Linux 的 `dma_rmb()` 和 `dma_wmb()` 将分别映射为 FENCE R,R 和 FENCE W,W，这是因为 RISC-V Unix 平台要求一致性 DMA。然而，对于具有非一致性 DMA 的平台，这些宏将映射为 FENCE RI,RI 和 FENCE WO,WO。在这类平台上，还可能需要机制来刷新或失效缓存行，这些机制通常是设备特定的，且可能在未来的 ISA 扩展中得到标准化。

Linux 的释放操作映射可能比实际所需的更强，但这是为了确保 Linux 在需要时能提供比直观映射更强的顺序保障。特别是在撰写本文时，Linux 正在积极探讨是否要求在同一硬件线程中的关键区访问和后续由相同同步对象保护的关键区访问之间，必须提供加载-加载、加载-存储和存储-存储的顺序。这种要求并非所有 FENCE RW,W/FENCE R,RW 映射与 `aq/rl` 映射的组合都能满足。为了解决这个问题，存在几种解决方案：

. 始终使用 FENCE RW,W/FENCE R,RW，不使用 `aq/rl`。这种方案能够满足基本需求，但并不理想，因为它忽视了 `aq/rl` 修饰符的作用。
. 始终使用 `aq/rl`，不使用 FENCE RW,W/FENCE R,RW。由于缺少带有 `aq` 和 `rl` 修饰符的加载和存储操作码，这种方案目前不可行。
. 加强释放操作的映射，使其在任何获取映射存在时，能够强制执行所需的顺序。当前推荐的解决方案正是这一方案，也是<<linuxmappings>>中显示的解决方案。

RVWMO 映射: (a) lw a0, 0(s0) (b) fence.tso // vs. fence rw,w (c) sd x0,0(s1) ... loop: (d) amoswap.d.aq a1,t1,0(s1) bnez a1,loop (e) lw a2,0(s2)

例如，Linux 社区正在讨论的关键区顺序规则要求 (a) 在 <<lkmm_ll>> 中排在 (e) 之前。如果这是必需的，(b) 映射为 FENCE RW,W 将无法提供足够的顺序保证。因此，随着 Linux 内核内存模型的进一步发展，映射可能会有所变化。

[[lkmm_ll]]
.Linux 中关键区之间的顺序
[source%linenums,asm]
----
Linux 代码:
(a) int r0 = *x;
       (bc) spin_unlock(y, 0);
....
....
(d) spin_lock(y);
(e) int r1 = *z;

RVWMO 映射:
(a) lw a0, 0(s0)
(b) fence.tso // vs. fence rw,w
(c) sd x0,0(s1)
....
loop:
(d) amoswap.d.aq a1,t1,0(s1)
bnez a1,loop
(e) lw a2,0(s2)
----

<<c11mappings>> 提供了 C11/C++11 原子操作到 RISC-V 内存指令的映射。如果引入带有 _aq_ 和 _rl_ 修饰符的加载和存储操作码，那么<<c11mappings_hypothetical>>中的映射将足够。然而请注意，只有当 `atomic_<op>(memory_order_seq_cst)` 使用同时设置了 _aq_ 和 _rl_ 的LR进行映射时，这两种映射才能正确互操作。
更重要的是，<<c11mappings>>中的顺序一致存储，后跟<<c11mappings_hypothetical>>中的顺序一致加载，除非通过添加第二个 fence 或将存储映射到 `amoswap.rl` 来加强<<c11mappings>>中的存储映射，否则可以重新排序。

[[c11mappings]]
.从 C/C++ 原语到 RISC-V 原语的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===

!C/C++ 构造 !RVWMO 映射

!非原子加载 !`l{b|h|w|d}`

!`atomic_load(memory_order_relaxed)` !`l{b|h|w|d}`

!`atomic_load(memory_order_acquire)` !`l{b|h|w|d}; fence r,rw`

!`atomic_load(memory_order_seq_cst)` !`fence rw,rw; l{b|h|w|d}; fence r,rw`

!非原子存储 !`s{b|h|w|d}`

!`atomic_store(memory_order_relaxed)` !`s{b|h|w|d}`

!`atomic_store(memory_order_release)` !`fence rw,w; s{b|h|w|d}`

!`atomic_store(memory_order_seq_cst)` !`fence rw,w; s{b|h|w|d}`

!`atomic_thread_fence(memory_order_acquire)` !`fence r,rw`

!`atomic_thread_fence(memory_order_release)` !`fence rw,w`

!`atomic_thread_fence(memory_order_acq_rel)` !`fence.tso`

!`atomic_thread_fence(memory_order_seq_cst)` !`fence rw,rw`

!C/C++ 构造 !RVWMO AMO 映射

!`atomic_<op>(memory_order_relaxed)` !`amo<op>.{w|d}`

!`atomic_<op>(memory_order_acquire)` !`amo<op>.{w|d}.aq`

!`atomic_<op>(memory_order_release)` !`amo<op>.{w|d}.rl`

!`atomic_<op>(memory_order_acq_rel)` !`amo<op>.{w|d}.aqrl`

!`atomic_<op>(memory_order_seq_cst)` !`amo<op>.{w|d}.aqrl`

!C/C++ 构造 !RVWMO LR/SC 映射

!`atomic_<op>(memory_order_relaxed)` !`loop:lr.{w|d}; <op>; sc.{w|d};`

! !`bnez loop`

!`atomic_<op>(memory_order_acquire)` !`loop:lr.{w|d}.aq; <op>; sc.{w|d};`

! !`bnez loop`

!`atomic_<op>(memory_order_release)` !`loop:lr.{w|d}; <op>; sc.{w|d}.rl;`

! !`bnez loop`

!`atomic_<op>(memory_order_acq_rel)` !`loop:lr.{w|d}.aq; <op>; sc.{w|d}.rl;`

! !`bnez loop`

!`atomic_<op>(memory_order_seq_cst)` !`loop:lr.{w|d}.aqrl; <op>;`

! !`sc.{w|d}.rl; bnez loop`

|===

[[c11mappings_hypothetical]]
.假设引入本地加载-获取和存储-释放操作码时，从C/C++原语到RISC-V原语的映射
[%autowidth,float="center",align="center",cols="<,<",options="header",separator=!]
|===
!C/C++ 构造 !RVWMO 映射

!非原子加载 !`l{b|h|w|d}`

!`atomic_load(memory_order_relaxed)` !`l{b|h|w|d}`

!`atomic_load(memory_order_acquire)` !`l{b|h|w|d}.aq`

!`atomic_load(memory_order_seq_cst)` !`l{b|h|w|d}.aq`

!非原子存储 !`s{b|h|w|d}`

!`atomic_store(memory_order_relaxed)` !`s{b|h|w|d}`

!`atomic_store(memory_order_release)` !`s{b|h|w|d}.rl`

!`atomic_store(memory_order_seq_cst)` !`s{b|h|w|d}.rl`

!`atomic_thread_fence(memory_order_acquire)` !`fence r,rw`

!`atomic_thread_fence(memory_order_release)` !`fence rw,w`

!`atomic_thread_fence(memory_order_acq_rel)` !`fence.tso`

!`atomic_thread_fence(memory_order_seq_cst)` !`fence rw,rw`

!C/C++ 构造 !RVWMO AMO 映射

!`atomic_<op>(memory_order_relaxed)` !`amo<op>.{w|d}`

!`atomic_<op>(memory_order_acquire)` !`amo<op>.{w|d}.aq`

!`atomic_<op>(memory_order_release)` !`amo<op>.{w|d}.rl`

!`atomic_<op>(memory_order_acq_rel)` !`amo<op>.{w|d}.aqrl`

!`atomic_<op>(memory_order_seq_cst)` !`amo<op>.{w|d}.aqrl`

!C/C++ 构造 !RVWMO LR/SC 映射

!`atomic_<op>(memory_order_relaxed)` !`lr.{w|d}; <op>; sc.{w|d}`

!`atomic_<op>(memory_order_acquire)` !`lr.{w|d}.aq; <op>; sc.{w|d}`

!`atomic_<op>(memory_order_release)` !`lr.{w|d}; <op>; sc.{w|d}.rl`

!`atomic_<op>(memory_order_acq_rel)` !`lr.{w|d}.aq; <op>; sc.{w|d}.rl`

!`atomic_<op>(memory_order_seq_cst)` !`lr.{w|d}.aq* <op>; sc.{w|d}.rl`

2+!`*` 必须是 `lr.{w|d}.aqrl` 以便与按<<c11mappings>>映射的代码互操作
|===

任何 AMO 都可以通过 LR/SC 对来模拟，但要确保从 LR 开始的 PPO 顺序会从 SC 开始，并且从 SC 结束的 PPO 顺序会在 LR 结束时完成。LR 需要遵循 AMO 的数据依赖性，因为加载操作本身并没有数据依赖的概念。同时，确保同一硬件线程中的其他 FENCE R,R 操作也对 SC 起作用，否则 SC 无法遵守该 fence。模拟器可以通过将 AMO 映射为 `lr.aq; <op>; sc.aqrl` 来实现这一点，从而与其他用于完全有序原子操作的映射方式保持一致。

这些 C11/C++11 映射要求平台为所有内存提供以下物理内存属性（如 RISC-V 特权 ISA 中定义）：

* 主内存
* 一致性
* AMOArithmetic
* RsrvEventual

具有不同属性的平台可能需要不同的映射，或需要特定平台的软件（例如，内存映射 I/O）。

=== 实现指南

RVWMO 和 RVTSO 内存模型允许微架构使用复杂的推测技术和其他优化手段来提升性能，而不会排除这些技术的使用。同时，这些模型并不要求硬件采用特定的缓存层次结构或一致性协议。它们主要关注可以暴露给软件的行为，允许硬件在满足内存模型规则的前提下自由选择流水线设计、一致或非一致的缓存层次结构、片上互连等。为了帮助架构师和程序员理解如何实现这些规则，本节提供了相关的指导建议。

RVWMO 和 RVTSO 都实现了多副本原子性（或类似的多副本原子性）：任何存储值一旦对发出该存储的硬件线程以外的其他硬件线程可见，就必须对所有其他硬件线程也可见。换句话说，硬件线程可以在其之前存储的值对所有硬件线程可见之前，从自己的存储中转发该值，但不能提前向其他硬件线程转发。多副本原子性可以通过多种方式实现，可能是由于缓存和存储缓冲区的物理设计，也可能是通过单写入者/多读取者缓存一致性协议，或其他机制来强制执行。

虽然多副本原子性确实对微架构施加了某些限制，但它是避免内存模型变得过于复杂的关键因素之一。例如，硬件线程不能从其他硬件线程的私有存储缓冲区中转发值，除非这种操作不会导致架构中出现新的非法行为。同样，缓存一致性协议要求，在将一个值从一个硬件线程转发到另一个硬件线程之前，必须确保其他缓存中的旧副本已被失效处理。这意味着缓存的一致性操作是顺序的，不允许提前转发数据。

当然，微架构可以通过推测执行或其他优化手段来违反这些规则，只要这些不合规的行为不会被程序员看到，并且不会影响程序的正确性。

在解释 RVWMO 中 PPO 规则时，从软件角度出发，我们期望：

* 程序员将定期和积极地使用 PPO 规则 <<overlapping-ordering, 1>> 和 <<overlapping-ordering, 4-8>>。
* 专家程序员将使用 PPO 规则 <<overlapping-ordering, 9-11>> 来加速重要数据结构的关键路径。
* 即使是专家程序员也很少或从不直接使用 PPO 规则 <<overlapping-ordering, 2-3>> 和 <<overlapping-ordering, 12-13>>。
这些规则包括在内是为了促进常见的微架构优化（规则 <<overlapping-ordering, 2>>）和描述的操作形式建模方法（规则 <<overlapping-ordering, 3>> 和 <<overlapping-ordering, 12-13>>） <<operational>>。它们还促进了从具有类似规则的其他架构移植代码的过程。

我们还期望从硬件角度来看：

* PPO 规则 <<overlapping-ordering, 1>> 和 <<overlapping-ordering, 3-6>> 反映了应该对架构师几乎没有惊喜的规则。
* PPO 规则 <<overlapping-ordering, 2>> 反映了一种自然且常见的硬件优化，但这种优化非常微妙，因此值得仔细检查。
* PPO 规则 <<overlapping-ordering, 7>> 可能对架构师来说并不立即明显，但它是标准的内存模型要求。
* 加载值公理、原子性公理和 PPO 规则 <<overlapping-ordering, 8-13>> 反映了大多数硬件实现自然会强制执行的规则，除非它们包含极端优化。当然，实现仍应确保仔细检查这些规则。硬件还必须确保语法依赖性不会被“优化掉”。

架构可以自由地以他们选择的任何保守方式实现任何内存模型规则。例如，硬件实现可以选择执行以下任何或所有操作：

* 将所有 fence 解释为 FENCE RW,RW（如果涉及 I/O，则为 FENCE IORW,IORW），无论实际设置了哪些位
* 将所有带有 PW 和 SR 的 fence 实现为 FENCE RW,RW（如果涉及 I/O，则为 FENCE IORW,IORW），因为 PW 和 SR 是四种可能的主内存排序组件中最昂贵的
* 按 <<memory_porting>> 中描述的方式模拟 _aq_ 和 _rl_
* 强制执行所有相同地址的加载-加载排序，即使存在诸如 `fri-rfi` 和 `RSW` 的模式
* 禁止从存储缓冲区中的存储值转发到同一地址的后续 AMO 或 LR
* 禁止从存储缓冲区中的 AMO 或 SC 值转发到同一地址的后续加载
* 在所有内存访问上实现 TSO，并忽略不包括 PW 和 SR 排序的任何主内存 fence（例如，Ztso 实现将这样做）
* 将所有原子操作实现为 RCsc 甚至完全有序，无论注释如何

实现 RVTSO 的架构可以安全地执行以下操作：

* 忽略所有不同时具有 PW 和 SR 的 fence（除非 fence 还对 I/O 排序）
* 忽略除规则 <<overlapping-ordering, 4>> 到 <<overlapping-ordering, 7>> 之外的所有 PPO 规则，因为在 RVTSO 假设下其余规则与其他 PPO 规则冗余

其他一般说明：

* 静默存储（即，写入与内存位置中已存在的值相同的存储）从内存模型的角度来看与任何其他存储行为相同。同样，实际上不改变内存中值的 AMO（例如，AMOMAX，其中 _rs2_ 中的值小于内存中当前的值）在语义上仍被视为存储操作。尝试实现静默存储的微架构必须注意确保仍然遵守内存模型，特别是在诸如 RSW <<mm-overlap>> 的情况下，这些情况往往与静默存储不兼容。
* 写入可以合并（即，对同一地址的两个连续写入可以合并）或替代（即，对同一地址的两个背靠背写入中的较早一个可以省略），只要结果行为不以其他方式违反内存模型语义。

可以通过以下示例理解写入替代的问题：

.写入替代试验，允许的执行
[float="center",align="center",cols=".^1a,.^1a",frame="none",grid="none",options="noheader"]
|===
|
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
!===
2+!Hart 0 2+^!Hart 1
2+!li t1, 3 2+^!li t3, 2
! !li t2, 1 ! !
!(a) !sw t1,0(s0) !(d) !lw a0,0(s1)
!(b) !fence w, w !(e) !sw a0,0(s0)
!(c) !sw t2,0(s1) !(f) !sw t3,0(s0)
!===
|
!===
//a! graphviz::images/graphviz/litmus_subsumption.txt[]
a! image::graphviz/litmus_subsumption.png[]
!===
|===

如所写，如果加载(d)读取值_1_，则(a)必须在全局内存顺序中先于(f)：

* (a)在全局内存顺序中先于(c)，因为规则2
* (c)在全局内存顺序中先于(d)，因为加载值公理
* (d)在全局内存顺序中先于(e)，因为规则7
* (e)在全局内存顺序中先于(f)，因为规则1

换句话说，地址在 `s0` 中的内存位置的最终值必须是 _2_（由存储(f)写入的值），而不能是 _3_（由存储(a)写入的值）。

在某些情况下，过于激进的微架构可能会错误地选择丢弃 (e)，因为 (f) 替代了它。这会导致 (d) 和 (f) 之间的依赖关系被破坏，从而影响到 (a) 和 (f) 之间的依赖关系。这样的行为违反了内存模型规则，因此是不被允许的。不过，如果 (d) 和 (e) 之间没有数据依赖性，那么写入替代的做法是合法的。

==== 可能的未来扩展

我们预计以下任何或所有可能的未来扩展都将与RVWMO内存模型兼容：

* "V" 向量ISA扩展
* "J" JIT扩展
* 带有 _aq_ 和 _rl_ 设置的加载和存储操作码的本地编码
* 限制到某些地址的fence
* 缓存写回/刷新/失效等指令

[[discrepancies]]
=== 已知问题

[[mixedrsw]]
==== 混合大小RSW

[[rsw1]]
.混合大小差异（公理模型允许，操作模型禁止）
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
|===
2+|Hart 0 2+^|Hart 1
2+|li t1, 1 2+^|li t1, 1
|(a) |lw a0,0(s0) |(d) |lw a1,0(s1)
|(b) |fence rw,rw |(e) |amoswap.w.rl a2,t1,0(s2)
|(c) |sw t1,0(s1) |(f) |ld a3,0(s2)
| | |(g) |lw a4,4(s2)
| | | |xor a5,a4,a4
| | | |add s0,s0,a5
| | |(h) |sw t1,0(s0)
4+|结果：`a0=1`，`a1=1`，`a2=0`，`a3=1`，`a4=0`
|===

[[rsw2]]
.混合大小差异（公理模型允许，操作模型禁止）
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header"]
|===
2+|Hart 0 2+^|Hart 1 
2+|li t1, 1 2+^|li t1, 1
|(a) |lw a0,0(s0) |(d) |ld a1,0(s1)
|(b) |fence rw,rw |(e) |lw a2,4(s1)
|(c) |sw t1,0(s1) | |xor a3,a2,a2
| | | |add s0,s0,a3
| | |(f) |sw t1,0(s0)
4+|结果：`a0=1`，`a1=1`，`a2=0`
|===

[[rsw3]]
.混合大小差异（公理模型允许，操作模型禁止）
[%autowidth,float="center",align="center",cols="^,<,^,<",options="header",]
|===
2+|Hart 0 2+^|Hart 1
2+|li t1, 1 2+^|li t1, 1
|(a) |lw a0,0(s0) |(d) |sw t1,4(s1)
|(b) |fence rw,rw |(e) |ld a1,0(s1)
|(c) |sw t1,0(s1) |(f) |lw a2,4(s1)
| | | |xor a3,a2,a2
| | | |add s0,s0,a3
| | |(g) |sw t1,0(s0)
4+|结果：`a0=1`，`a1=0x100000001`，`a2=1`
|===

在 <<rsw1>>-<<rsw3>> 显示的混合大小 RSW 变体家族中，操作规范与公理规范之间存在已知的差异。为了弥补这个差异，我们可能需要增加如下的 PPO 规则：假如内存操作 _a_ 在程序顺序中先于内存操作 _b_（同时也在全局内存顺序中），则 _a_ 必须在 _b_ 之前执行，且 _a_ 和 _b_ 必须都访问常规主内存（而非 I/O 区域），_a_ 为加载操作，_b_ 为存储操作，且存在一个加载操作 _m_ 在 _a_ 和 _b_ 之间，_a_ 和 _m_ 都读取字节 _x_，同时在 _a_ 和 _m_ 之间不会有写入 _x_ 的存储操作，且 _m_ 必须在 PPO 中先于 _b_。换句话说，在 _herd_ 语法中，我们可以考虑在 PPO 中加入 `(po-loc & rsw);ppo;[W]`。很多实现已经自然地强制执行这一顺序。因此，即使此规则尚未成为正式规范，我们依然建议实现者执行它，以保证未来与可能加入 RVWMO 的规则兼容。

